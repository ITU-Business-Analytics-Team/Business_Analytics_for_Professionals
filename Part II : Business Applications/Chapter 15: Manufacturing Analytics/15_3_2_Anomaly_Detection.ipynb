{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "15.3.2. Anomaly Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITU-Business-Analytics-Team/Business_Analytics_for_Professionals/blob/main/Part%20II%20%3A%20Business%20Applications/Chapter%2015%3A%20Manufacturing%20Analytics/15_3_2_Anomaly_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLkkDA8XbjvZ"
      },
      "source": [
        "# **Manufacturing Analytics**\n",
        "## Predictive Maintenance\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Anomaly Detection"
      ],
      "metadata": {
        "id": "xLQsXylNNeNg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHxw8G3WErdc"
      },
      "source": [
        "### Dataset Explanation\n",
        "*data link: https://data.nasa.gov/dataset/C-MAPSS-Aircraft-Engine-Simulator-Data/xaut-bemq*\n",
        "\n",
        "The given dataset was generated by the C-MAPSS simulator. The data includes the initial setting data of 100 different turbofans and the data of the sensors on the turbofans. These are time-series data. The main purpose of the models to be established is to make predictive maintenance estimations by the turbofan company. Estimations were made by establishing clustering models using the data \n",
        "\n",
        "---\n",
        "\n",
        "described below.\n",
        "\n",
        "* time, in cycles  Engine working cycle\n",
        "-os1              operational settings 1 for engine performance\n",
        "-os2              operational settings 2 for engine performance\n",
        "-os3              operational settings 3 for engine performance\n",
        "-sensor_01        Measurement data of Sensor 1\n",
        "-sensor_02        Measurement data of Sensor 2\n",
        "-sensor_03.       Measurement data of Sensor 3\n",
        "-    .\n",
        "-    .\n",
        "-    .\n",
        "-sensor_25        Measurement data of Sensor 25\n",
        "-sensor_26        Measurement data of Sensor 26\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NdTtg9Ibm1u"
      },
      "source": [
        "### **Anomaly_Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaxKvpDbEMDJ"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "#!pip install missingno\n",
        "import missingno as msno\n",
        "\n",
        "## Libraries and Functions For Clustering  ##\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from pyod.models.auto_encoder import AutoEncoder\n",
        "\n",
        "from sklearn.metrics import adjusted_rand_score, recall_score, roc_auc_score, fowlkes_mallows_score, silhouette_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nKY0LM-WPwnB",
        "outputId": "526dd6e1-422e-48ea-8edf-f17866b57c76"
      },
      "source": [
        "# The csv file to be used in model training has been imported.\n",
        "url = \"https://drive.google.com/file/d/1_GFvONFKen0gV8oTA8zd4kxga8E-JfS8/view?usp=sharing\"\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "# Columns with no data and only one data has been found to be excluded from the model.\n",
        "# If there is no change in the data, there is no information that the model can learn from.\n",
        "na_list = df.columns[df.isna().any()].tolist()\n",
        "const_list = [col for col in df.columns if len(df[col].unique()) <= 2] \n",
        "df.drop(columns=na_list+const_list,axis=1, inplace=True)\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_num</th>\n",
              "      <th>cycle_time</th>\n",
              "      <th>os1</th>\n",
              "      <th>os2</th>\n",
              "      <th>sensor_02</th>\n",
              "      <th>sensor_03</th>\n",
              "      <th>sensor_04</th>\n",
              "      <th>sensor_07</th>\n",
              "      <th>sensor_08</th>\n",
              "      <th>sensor_09</th>\n",
              "      <th>sensor_11</th>\n",
              "      <th>sensor_12</th>\n",
              "      <th>sensor_13</th>\n",
              "      <th>sensor_14</th>\n",
              "      <th>sensor_15</th>\n",
              "      <th>sensor_17</th>\n",
              "      <th>sensor_20</th>\n",
              "      <th>sensor_21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "      <td>20631.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>51.506568</td>\n",
              "      <td>108.807862</td>\n",
              "      <td>-0.000009</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>642.680934</td>\n",
              "      <td>1590.523119</td>\n",
              "      <td>1408.933782</td>\n",
              "      <td>553.367711</td>\n",
              "      <td>2388.096652</td>\n",
              "      <td>9065.242941</td>\n",
              "      <td>47.541168</td>\n",
              "      <td>521.413470</td>\n",
              "      <td>2388.096152</td>\n",
              "      <td>8143.752722</td>\n",
              "      <td>8.442146</td>\n",
              "      <td>393.210654</td>\n",
              "      <td>38.816271</td>\n",
              "      <td>23.289705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>29.227633</td>\n",
              "      <td>68.880990</td>\n",
              "      <td>0.002187</td>\n",
              "      <td>0.000293</td>\n",
              "      <td>0.500053</td>\n",
              "      <td>6.131150</td>\n",
              "      <td>9.000605</td>\n",
              "      <td>0.885092</td>\n",
              "      <td>0.070985</td>\n",
              "      <td>22.082880</td>\n",
              "      <td>0.267087</td>\n",
              "      <td>0.737553</td>\n",
              "      <td>0.071919</td>\n",
              "      <td>19.076176</td>\n",
              "      <td>0.037505</td>\n",
              "      <td>1.548763</td>\n",
              "      <td>0.180746</td>\n",
              "      <td>0.108251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.008700</td>\n",
              "      <td>-0.000600</td>\n",
              "      <td>641.210000</td>\n",
              "      <td>1571.040000</td>\n",
              "      <td>1382.250000</td>\n",
              "      <td>549.850000</td>\n",
              "      <td>2387.900000</td>\n",
              "      <td>9021.730000</td>\n",
              "      <td>46.850000</td>\n",
              "      <td>518.690000</td>\n",
              "      <td>2387.880000</td>\n",
              "      <td>8099.940000</td>\n",
              "      <td>8.324900</td>\n",
              "      <td>388.000000</td>\n",
              "      <td>38.140000</td>\n",
              "      <td>22.894200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>26.000000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>-0.001500</td>\n",
              "      <td>-0.000200</td>\n",
              "      <td>642.325000</td>\n",
              "      <td>1586.260000</td>\n",
              "      <td>1402.360000</td>\n",
              "      <td>552.810000</td>\n",
              "      <td>2388.050000</td>\n",
              "      <td>9053.100000</td>\n",
              "      <td>47.350000</td>\n",
              "      <td>520.960000</td>\n",
              "      <td>2388.040000</td>\n",
              "      <td>8133.245000</td>\n",
              "      <td>8.414900</td>\n",
              "      <td>392.000000</td>\n",
              "      <td>38.700000</td>\n",
              "      <td>23.221800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>52.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>642.640000</td>\n",
              "      <td>1590.100000</td>\n",
              "      <td>1408.040000</td>\n",
              "      <td>553.440000</td>\n",
              "      <td>2388.090000</td>\n",
              "      <td>9060.660000</td>\n",
              "      <td>47.510000</td>\n",
              "      <td>521.480000</td>\n",
              "      <td>2388.090000</td>\n",
              "      <td>8140.540000</td>\n",
              "      <td>8.438900</td>\n",
              "      <td>393.000000</td>\n",
              "      <td>38.830000</td>\n",
              "      <td>23.297900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>643.000000</td>\n",
              "      <td>1594.380000</td>\n",
              "      <td>1414.555000</td>\n",
              "      <td>554.010000</td>\n",
              "      <td>2388.140000</td>\n",
              "      <td>9069.420000</td>\n",
              "      <td>47.700000</td>\n",
              "      <td>521.950000</td>\n",
              "      <td>2388.140000</td>\n",
              "      <td>8148.310000</td>\n",
              "      <td>8.465600</td>\n",
              "      <td>394.000000</td>\n",
              "      <td>38.950000</td>\n",
              "      <td>23.366800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>362.000000</td>\n",
              "      <td>0.008700</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>644.530000</td>\n",
              "      <td>1616.910000</td>\n",
              "      <td>1441.490000</td>\n",
              "      <td>556.060000</td>\n",
              "      <td>2388.560000</td>\n",
              "      <td>9244.590000</td>\n",
              "      <td>48.530000</td>\n",
              "      <td>523.380000</td>\n",
              "      <td>2388.560000</td>\n",
              "      <td>8293.720000</td>\n",
              "      <td>8.584800</td>\n",
              "      <td>400.000000</td>\n",
              "      <td>39.430000</td>\n",
              "      <td>23.618400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           unit_num    cycle_time  ...     sensor_20     sensor_21\n",
              "count  20631.000000  20631.000000  ...  20631.000000  20631.000000\n",
              "mean      51.506568    108.807862  ...     38.816271     23.289705\n",
              "std       29.227633     68.880990  ...      0.180746      0.108251\n",
              "min        1.000000      1.000000  ...     38.140000     22.894200\n",
              "25%       26.000000     52.000000  ...     38.700000     23.221800\n",
              "50%       52.000000    104.000000  ...     38.830000     23.297900\n",
              "75%       77.000000    156.000000  ...     38.950000     23.366800\n",
              "max      100.000000    362.000000  ...     39.430000     23.618400\n",
              "\n",
              "[8 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3gduO_GEMDQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4205d43f-9856-4e72-a4f2-5c4443535cba"
      },
      "source": [
        "# In order to establish the regression model, it is necessary to calculate the remaining useful life of the turbofans.\n",
        "units = df[\"unit_num\"].unique().tolist()\n",
        "dicti = {}\n",
        "for i in units:\n",
        "    dicti[i] = df[df[\"unit_num\"] == i][\"cycle_time\"].max() \n",
        "df[\"RUL\"] = df[\"unit_num\"].apply(lambda key: dicti[key]) - df[\"cycle_time\"]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unit_num</th>\n",
              "      <th>cycle_time</th>\n",
              "      <th>os1</th>\n",
              "      <th>os2</th>\n",
              "      <th>sensor_02</th>\n",
              "      <th>sensor_03</th>\n",
              "      <th>sensor_04</th>\n",
              "      <th>sensor_07</th>\n",
              "      <th>sensor_08</th>\n",
              "      <th>sensor_09</th>\n",
              "      <th>sensor_11</th>\n",
              "      <th>sensor_12</th>\n",
              "      <th>sensor_13</th>\n",
              "      <th>sensor_14</th>\n",
              "      <th>sensor_15</th>\n",
              "      <th>sensor_17</th>\n",
              "      <th>sensor_20</th>\n",
              "      <th>sensor_21</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>392</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>392</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>390</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>392</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>393</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   unit_num  cycle_time     os1     os2  ...  sensor_17  sensor_20  sensor_21  RUL\n",
              "0         1           1 -0.0007 -0.0004  ...        392      39.06    23.4190  191\n",
              "1         1           2  0.0019 -0.0003  ...        392      39.00    23.4236  190\n",
              "2         1           3 -0.0043  0.0003  ...        390      38.95    23.3442  189\n",
              "3         1           4  0.0007  0.0000  ...        392      38.88    23.3739  188\n",
              "4         1           5 -0.0019 -0.0002  ...        393      38.90    23.4044  187\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPRDiGhgEMDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b55ec7-2022-4ebf-aee2-4cf741ef6789"
      },
      "source": [
        "# In order to establish the clustering model, the threshold determined in the visualizations has been used. \n",
        "# The part that is above the threshold is called the class 0 which is functional RUL, \n",
        "# and the values that are below the threshold is called class 1 which is nonfunctional RUL.\n",
        "# This target column was used for evaluation metrics.\n",
        "df[\"RUL_clf\"] = [1 if i <= 40 else 0 for i in df[\"RUL\"] ]\n",
        "df[\"RUL_clf\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "20626    1\n",
              "20627    1\n",
              "20628    1\n",
              "20629    1\n",
              "20630    1\n",
              "Name: RUL_clf, Length: 20631, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxngmPUWEMDR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "90c7f350-3cbb-4ef2-da3f-679f5ffd1353"
      },
      "source": [
        "# The bar graph has been used to determine the class distribution in the data.\n",
        "sns.countplot(x=\"RUL_clf\",data=df)\n",
        "plt.show()\n",
        "print(df[\"RUL_clf\"].value_counts())\n",
        "df.drop(\"RUL\",axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    16531\n",
            "1     4100\n",
            "Name: RUL_clf, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8O2BSCgEMDS"
      },
      "source": [
        "# Performance metrics have been calculated to evaluate the trained model.\n",
        "\n",
        "def get_clf_model_metrics(model,actual,predicted):\n",
        "    \n",
        "    clf_metrics = {\n",
        "                        \"Adjusted Rand Score\": adjusted_rand_score(actual, predicted),\n",
        "                        \"Fowlkes Mallows Score\":fowlkes_mallows_score(actual, predicted),\n",
        "                        \"Recall Score\": recall_score(actual, predicted),\n",
        "                        \"Auc Score\": roc_auc_score(actual, predicted),     \n",
        "                  }\n",
        "    \n",
        "    df_clf_metrics = pd.DataFrame.from_dict(clf_metrics, orient='index')\n",
        "    df_clf_metrics.columns = [model]\n",
        "    \n",
        "    return df_clf_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdE0IVRsEMDT"
      },
      "source": [
        "# In order to train the model, X and y data has beeb prepared according to the outputs obtained from the data exploration section. \n",
        "# Afterwards, the dataset has been divided into training and test sets and the models has been trained with the training set.\n",
        "\n",
        "def fit_model(model, data):\n",
        "    \n",
        "    \n",
        "    X = df.drop([\"os1\",\"os2\",\"RUL_clf\",\"sensor_14\"],axis=1)\n",
        "    y = df[\"RUL_clf\"].values\n",
        "    \n",
        "    i = 0\n",
        "    \n",
        "    for name, clf in model.items():\n",
        "        print(\"Fitting model: \" + name)\n",
        "        clf.fit(X)\n",
        "        \n",
        "        if name == \"K-Means\":\n",
        "            y_pred = clf.predict(X)\n",
        "            y_pred = (y_pred == 0).astype(int)\n",
        "            \n",
        "        elif name == \"Auto Encoder\":\n",
        "            y_pred = clf.predict(X)\n",
        "            \n",
        "        else:\n",
        "            y_pred = clf.predict(X)\n",
        "            y_pred = (y_pred == -1).astype(int)\n",
        "            \n",
        "        if i == 0:\n",
        "            metrics = get_clf_model_metrics(name, y, y_pred)\n",
        "            print(metrics)\n",
        "            \n",
        "        elif i != 0:\n",
        "            new_metric = get_clf_model_metrics(name, y, y_pred)\n",
        "            print(new_metric)\n",
        "            metrics = pd.concat([metrics, new_metric],axis=1)\n",
        "            \n",
        "        i= i+1\n",
        "        print(\"\\n\\n\")\n",
        "        \n",
        "    return metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1GkWGKSEMDU"
      },
      "source": [
        "model = {    \n",
        "     \"One Class SVM\": OneClassSVM(),\n",
        "     \"Local Outlier Factor\": LocalOutlierFactor(contamination=0.248, novelty=True),\n",
        "     \"K-Means\": KMeans(n_clusters = 2, random_state = 42),\n",
        "     \"Isolation Forest\": IsolationForest(n_estimators=100, random_state=42, n_jobs=-1, contamination=0.248),\n",
        "     \"Auto Encoder\": AutoEncoder(hidden_neurons =[20, 12, 12, 20],contamination = 0.248),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DGxyMLcEMDV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "69e60beb-7573-438e-8463-199b094bb3d0"
      },
      "source": [
        "fit_model(model, df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model: One Class SVM\n",
            "                       One Class SVM\n",
            "Adjusted Rand Score         0.027017\n",
            "Fowlkes Mallows Score       0.595300\n",
            "Recall Score                0.707317\n",
            "Auc Score                   0.629262\n",
            "\n",
            "\n",
            "\n",
            "Fitting model: Local Outlier Factor\n",
            "                       Local Outlier Factor\n",
            "Adjusted Rand Score                0.005806\n",
            "Fowlkes Mallows Score              0.666761\n",
            "Recall Score                       0.237317\n",
            "Auc Score                          0.506143\n",
            "\n",
            "\n",
            "\n",
            "Fitting model: K-Means\n",
            "                        K-Means\n",
            "Adjusted Rand Score    0.252667\n",
            "Fowlkes Mallows Score  0.695814\n",
            "Recall Score           0.963171\n",
            "Auc Score              0.832623\n",
            "\n",
            "\n",
            "\n",
            "Fitting model: Isolation Forest\n",
            "                       Isolation Forest\n",
            "Adjusted Rand Score            0.370995\n",
            "Fowlkes Mallows Score          0.782479\n",
            "Recall Score                   0.690000\n",
            "Auc Score                      0.775797\n",
            "\n",
            "\n",
            "\n",
            "Fitting model: Auto Encoder\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                320       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 12)                252       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 12)                156       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 20)                260       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 15)                315       \n",
            "=================================================================\n",
            "Total params: 1,783\n",
            "Trainable params: 1,783\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/100\n",
            "581/581 [==============================] - 3s 2ms/step - loss: 1.5485 - val_loss: 1.1412\n",
            "Epoch 2/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.1209 - val_loss: 1.0614\n",
            "Epoch 3/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0732 - val_loss: 1.0334\n",
            "Epoch 4/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0520 - val_loss: 1.0185\n",
            "Epoch 5/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0394 - val_loss: 1.0089\n",
            "Epoch 6/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0310 - val_loss: 1.0020\n",
            "Epoch 7/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0248 - val_loss: 0.9969\n",
            "Epoch 8/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0200 - val_loss: 0.9930\n",
            "Epoch 9/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0165 - val_loss: 0.9898\n",
            "Epoch 10/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0135 - val_loss: 0.9873\n",
            "Epoch 11/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0114 - val_loss: 0.9853\n",
            "Epoch 12/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0095 - val_loss: 0.9837\n",
            "Epoch 13/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0081 - val_loss: 0.9825\n",
            "Epoch 14/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0070 - val_loss: 0.9815\n",
            "Epoch 15/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0061 - val_loss: 0.9807\n",
            "Epoch 16/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0054 - val_loss: 0.9802\n",
            "Epoch 17/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0049 - val_loss: 0.9796\n",
            "Epoch 18/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0044 - val_loss: 0.9792\n",
            "Epoch 19/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0041 - val_loss: 0.9788\n",
            "Epoch 20/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0038 - val_loss: 0.9786\n",
            "Epoch 21/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0036 - val_loss: 0.9784\n",
            "Epoch 22/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0035 - val_loss: 0.9782\n",
            "Epoch 23/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0033 - val_loss: 0.9780\n",
            "Epoch 24/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0032 - val_loss: 0.9779\n",
            "Epoch 25/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0031 - val_loss: 0.9778\n",
            "Epoch 26/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0030 - val_loss: 0.9778\n",
            "Epoch 27/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0030 - val_loss: 0.9777\n",
            "Epoch 28/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0029 - val_loss: 0.9776\n",
            "Epoch 29/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0029 - val_loss: 0.9775\n",
            "Epoch 30/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 0.9775\n",
            "Epoch 31/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 0.9775\n",
            "Epoch 32/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 0.9774\n",
            "Epoch 33/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0028 - val_loss: 0.9774\n",
            "Epoch 34/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9774\n",
            "Epoch 35/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9773\n",
            "Epoch 36/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9773\n",
            "Epoch 37/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9773\n",
            "Epoch 38/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9773\n",
            "Epoch 39/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9773\n",
            "Epoch 40/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0027 - val_loss: 0.9772\n",
            "Epoch 41/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 42/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 43/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 44/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 45/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 46/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 47/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 48/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 49/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 50/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9772\n",
            "Epoch 51/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 52/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 53/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 54/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 55/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 56/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 57/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 58/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 59/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 60/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 61/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 62/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 63/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 64/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 65/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 66/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 67/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 68/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 69/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 70/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 71/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 72/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 73/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 74/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 75/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 76/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 77/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 78/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 79/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 80/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 81/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 82/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 83/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 84/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 85/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 86/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 87/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 88/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 89/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 90/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 91/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 92/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 93/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 94/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 95/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 96/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 97/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 98/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 99/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "Epoch 100/100\n",
            "581/581 [==============================] - 1s 2ms/step - loss: 1.0026 - val_loss: 0.9771\n",
            "                       Auto Encoder\n",
            "Adjusted Rand Score        0.383669\n",
            "Fowlkes Mallows Score      0.786880\n",
            "Recall Score               0.700976\n",
            "Auc Score                  0.782646\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>One Class SVM</th>\n",
              "      <th>Local Outlier Factor</th>\n",
              "      <th>K-Means</th>\n",
              "      <th>Isolation Forest</th>\n",
              "      <th>Auto Encoder</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Adjusted Rand Score</th>\n",
              "      <td>0.027017</td>\n",
              "      <td>0.005806</td>\n",
              "      <td>0.252667</td>\n",
              "      <td>0.370995</td>\n",
              "      <td>0.383669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fowlkes Mallows Score</th>\n",
              "      <td>0.595300</td>\n",
              "      <td>0.666761</td>\n",
              "      <td>0.695814</td>\n",
              "      <td>0.782479</td>\n",
              "      <td>0.786880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recall Score</th>\n",
              "      <td>0.707317</td>\n",
              "      <td>0.237317</td>\n",
              "      <td>0.963171</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.700976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Auc Score</th>\n",
              "      <td>0.629262</td>\n",
              "      <td>0.506143</td>\n",
              "      <td>0.832623</td>\n",
              "      <td>0.775797</td>\n",
              "      <td>0.782646</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       One Class SVM  ...  Auto Encoder\n",
              "Adjusted Rand Score         0.027017  ...      0.383669\n",
              "Fowlkes Mallows Score       0.595300  ...      0.786880\n",
              "Recall Score                0.707317  ...      0.700976\n",
              "Auc Score                   0.629262  ...      0.782646\n",
              "\n",
              "[4 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwXQP72qHzvq"
      },
      "source": [
        "#### Classification Model Evaluation\n",
        "\n",
        "5 different algorithms were trained and tested with test sets. As a result, the metrics used for model evaluation were calculated. The metrics are listed in the table from smallest to largest. Accurate prediction of failure moments of turbofans is more important than wrong prediction. The recall score indicates how many of those predicted as positive clusters actually belonged to the positive cluster. The positive set represents our engines that are close to failure within our application. Therefore, recall is the most important criterion in practice. According to the Recall metric, K-means were significantly better than other models in practice, with close values ​​found for autoencoders, single-class SVM, and isolation forests. At this point, the Auc score was checked to observe how successful the two clusters were in separating them from each other. Under these conditions, K-means was the most suitable first model for anomaly detection application, while the second algorithm was determined as autoencoder neural networks."
      ]
    }
  ]
}