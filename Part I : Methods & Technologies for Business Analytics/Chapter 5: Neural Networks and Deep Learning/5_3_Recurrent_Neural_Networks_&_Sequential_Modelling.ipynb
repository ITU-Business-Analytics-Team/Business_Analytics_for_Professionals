{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "5.3. Recurrent Neural Networks & Sequential Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITU-Business-Analytics-Team/Business_Analytics_for_Professionals/blob/main/Part%20I%20%3A%20Methods%20%26%20Technologies%20for%20Business%20Analytics/Chapter%205%3A%20Neural%20Networks%20and%20Deep%20Learning/5_3_Recurrent_Neural_Networks_%26_Sequential_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fADkWq6rb7WQ"
      },
      "source": [
        "# **Neural Networks and Deep Learning**\n",
        "## Recurrent Neural Networks & Sequential Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_2MGsMjcF9O"
      },
      "source": [
        "### **Example: Power Consumption Forecast**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eba-UHbGPuME"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Install tensorflow if not \n",
        "#!pip install tensorflow==2.2\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM,Dropout, Activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "DX-02YcicRwb",
        "outputId": "5775343d-002a-4c02-da39-abb1a574eac7"
      },
      "source": [
        "# Import Data  \n",
        "url=   'https://drive.google.com/file/d/1FJyED9Rh6UHDFvcY1YxHzGn5TqSq3kzu/view?usp=sharing'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "df = pd.read_csv(path,sep=\";\")\n",
        "df.set_index(['Date','Time'], inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">16/12/2006</th>\n",
              "      <th>17:24:00</th>\n",
              "      <td>4.216</td>\n",
              "      <td>0.418</td>\n",
              "      <td>234.840</td>\n",
              "      <td>18.400</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17:25:00</th>\n",
              "      <td>5.360</td>\n",
              "      <td>0.436</td>\n",
              "      <td>233.630</td>\n",
              "      <td>23.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17:26:00</th>\n",
              "      <td>5.374</td>\n",
              "      <td>0.498</td>\n",
              "      <td>233.290</td>\n",
              "      <td>23.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17:27:00</th>\n",
              "      <td>5.388</td>\n",
              "      <td>0.502</td>\n",
              "      <td>233.740</td>\n",
              "      <td>23.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17:28:00</th>\n",
              "      <td>3.666</td>\n",
              "      <td>0.528</td>\n",
              "      <td>235.680</td>\n",
              "      <td>15.800</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Global_active_power  ... Sub_metering_3\n",
              "Date       Time                          ...               \n",
              "16/12/2006 17:24:00               4.216  ...           17.0\n",
              "           17:25:00               5.360  ...           16.0\n",
              "           17:26:00               5.374  ...           17.0\n",
              "           17:27:00               5.388  ...           17.0\n",
              "           17:28:00               3.666  ...           17.0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSXbBnH3PuMJ"
      },
      "source": [
        "## Dataset Information\n",
        "Variable Name | Variable Description\n",
        "-------------------|------------------\n",
        "Global_active_power\t| The total active power consumed by the household (kilowatts)\n",
        "Global_reactive_power | The total reactive power consumed by the household (kilowatts)\n",
        "Voltage | Minute-averaged voltage (volts)\n",
        "Global_intensity | Household global minute-averaged current intensity (amperes)\n",
        "Sub_metering_1 | Active energy for kitchen (watt-hours of active energy)\n",
        "Sub_metering_2 | Active energy for laundry (watt-hours of active energy)\n",
        "Sub_metering_3 | Active energy for climate control systems (watt-hours of active energy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_hVAjB4PuML"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjDgw4blPuML"
      },
      "source": [
        "Missing values given '?' are changed to nan and variables are converted to numeric type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsHklDVaPuMM",
        "outputId": "c97ea01d-9450-471c-8d89-ca996d1a6aa7"
      },
      "source": [
        "df.replace('?', np.nan, inplace=True)\n",
        "cols = df.select_dtypes(exclude=['float']).columns\n",
        "df[cols] = df[cols].apply(pd.to_numeric, downcast='float', errors='coerce')\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Global_active_power      float32\n",
              "Global_reactive_power    float32\n",
              "Voltage                  float32\n",
              "Global_intensity         float32\n",
              "Sub_metering_1           float32\n",
              "Sub_metering_2           float32\n",
              "Sub_metering_3           float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCAruRW-PuMM"
      },
      "source": [
        "Next, remaning watt-hours are calculating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agtIt6LnPuMN"
      },
      "source": [
        "df['sub_metering_4'] = (df['Global_active_power'] * 1000 / 60) - (df['Sub_metering_1'] + df['Sub_metering_2'] + df['Sub_metering_2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBfnTDoAPuMO"
      },
      "source": [
        "The target variable is created to predict the next minute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEb_QLdaPuMO"
      },
      "source": [
        "df['Global_active_power_Next'] = df['Global_active_power'].shift(1)\n",
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWndpor8PuMP"
      },
      "source": [
        "X = df.drop(columns=['Global_active_power_Next'])\n",
        "y = df[['Global_active_power_Next']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmKJfodKPuMP",
        "outputId": "d13cac77-075f-449e-b7fc-66457dff5596"
      },
      "source": [
        "train_size = int(len(df) * 0.8)\n",
        "test_size = len(df) - train_size\n",
        "train_size, test_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7996, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ7IbE2fPuMQ"
      },
      "source": [
        "scaler_x = MinMaxScaler()\n",
        "X_norm = scaler_x.fit_transform(X)\n",
        "X_train, X_test = X_norm[:train_size], X_norm[train_size:]\n",
        "\n",
        "y_true = y[train_size:]\n",
        "scaler_y = MinMaxScaler()\n",
        "y_norm = scaler_y.fit_transform(y)\n",
        "y_train = y_norm[:train_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V81h4ZwPuMQ"
      },
      "source": [
        "The values of the previous 2 minutes will be used to predict the next minute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzBjNYQwPuMQ"
      },
      "source": [
        "lookback=2\n",
        "train_size = train_size - lookback + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1WN05hPPuMR"
      },
      "source": [
        "Preparing data for the LSTM method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvble8dcPuMR"
      },
      "source": [
        "X_all=[]\n",
        "y_all=[]\n",
        "for i in range(len(X_norm)-lookback + 1):\n",
        "    t=[]\n",
        "    for j in range(0,lookback):\n",
        "        t.append(X_norm[[(i+j)]])\n",
        "    X_all.append(t)\n",
        "    y_all.append(y_norm[i+ lookback - 1])\n",
        "\n",
        "X_all, y_all= np.array(X_all), np.array(y_all)\n",
        "\n",
        "y_pred=[]\n",
        "\n",
        "X_train= X_all[:train_size]\n",
        "X_test = X_all[train_size:train_size + test_size]\n",
        "if lookback!=0:\n",
        "    X_train = X_train.reshape(X_train.shape[0],lookback, X_train.shape[3])\n",
        "    X_test = X_test.reshape(X_test.shape[0],lookback, X_test.shape[3])\n",
        "else:\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[2])\n",
        "    \n",
        "y_train= y_all[:train_size]\n",
        "y_test= y_all[train_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26S9qXe7PuMS",
        "outputId": "582445c9-44a0-4f41-a4a2-7b08776755e8"
      },
      "source": [
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7995, 2, 8), (2000, 2, 8), (7995, 1), (2000, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOTGC_U_PuMS"
      },
      "source": [
        "## LSTM Multivariate Time Series Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgEkFoWyPuMS"
      },
      "source": [
        "units=4\n",
        "epochs=100\n",
        "batch_size=144"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dazn3CKXPuMT"
      },
      "source": [
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BmR4v_rYPuMT",
        "outputId": "b7adb5b8-e890-442e-cced-4123d901bc07"
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "## LSTM Model & Prediction ###############\n",
        "model = Sequential()\n",
        "\n",
        "model.add(LSTM(units=units, input_shape=(lookback,X_all.shape[3]), dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mae', optimizer='adam',metrics=['mae'])\n",
        "    \n",
        "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
        "# plot history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "y_pred= model.predict(X_test)\n",
        "\n",
        "##########################################\n",
        "        \n",
        "y_pred = np.array(y_pred).reshape(test_size,1)\n",
        "y_pred = scaler_y.inverse_transform(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "56/56 [==============================] - 3s 10ms/step - loss: 0.2518 - mae: 0.2518 - val_loss: 0.2728 - val_mae: 0.2728\n",
            "Epoch 2/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1741 - mae: 0.1741 - val_loss: 0.1994 - val_mae: 0.1994\n",
            "Epoch 3/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1365 - mae: 0.1365 - val_loss: 0.1530 - val_mae: 0.1530\n",
            "Epoch 4/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.1084 - mae: 0.1084 - val_loss: 0.1172 - val_mae: 0.1172\n",
            "Epoch 5/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0858 - mae: 0.0858 - val_loss: 0.0958 - val_mae: 0.0958\n",
            "Epoch 6/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0735 - mae: 0.0735 - val_loss: 0.0862 - val_mae: 0.0862\n",
            "Epoch 7/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0694 - mae: 0.0694 - val_loss: 0.0833 - val_mae: 0.0833\n",
            "Epoch 8/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0667 - mae: 0.0667 - val_loss: 0.0821 - val_mae: 0.0821\n",
            "Epoch 9/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0634 - mae: 0.0634 - val_loss: 0.0776 - val_mae: 0.0776\n",
            "Epoch 10/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0603 - mae: 0.0603 - val_loss: 0.0767 - val_mae: 0.0767\n",
            "Epoch 11/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0604 - mae: 0.0604 - val_loss: 0.0729 - val_mae: 0.0729\n",
            "Epoch 12/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0580 - mae: 0.0580 - val_loss: 0.0696 - val_mae: 0.0696\n",
            "Epoch 13/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0567 - mae: 0.0567 - val_loss: 0.0696 - val_mae: 0.0696\n",
            "Epoch 14/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0553 - mae: 0.0553 - val_loss: 0.0612 - val_mae: 0.0612\n",
            "Epoch 15/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0543 - mae: 0.0543 - val_loss: 0.0628 - val_mae: 0.0628\n",
            "Epoch 16/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0531 - mae: 0.0531 - val_loss: 0.0599 - val_mae: 0.0599\n",
            "Epoch 17/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0529 - mae: 0.0529 - val_loss: 0.0587 - val_mae: 0.0587\n",
            "Epoch 18/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0521 - mae: 0.0521 - val_loss: 0.0566 - val_mae: 0.0566\n",
            "Epoch 19/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0514 - mae: 0.0514 - val_loss: 0.0560 - val_mae: 0.0560\n",
            "Epoch 20/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0509 - mae: 0.0509 - val_loss: 0.0538 - val_mae: 0.0538\n",
            "Epoch 21/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0498 - mae: 0.0498 - val_loss: 0.0535 - val_mae: 0.0535\n",
            "Epoch 22/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0504 - val_mae: 0.0504\n",
            "Epoch 23/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0490 - mae: 0.0490 - val_loss: 0.0512 - val_mae: 0.0512\n",
            "Epoch 24/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0485 - mae: 0.0485 - val_loss: 0.0525 - val_mae: 0.0525\n",
            "Epoch 25/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0521 - val_mae: 0.0521\n",
            "Epoch 26/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0487 - mae: 0.0487 - val_loss: 0.0536 - val_mae: 0.0536\n",
            "Epoch 27/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0483 - mae: 0.0483 - val_loss: 0.0493 - val_mae: 0.0493\n",
            "Epoch 28/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0477 - mae: 0.0477 - val_loss: 0.0498 - val_mae: 0.0498\n",
            "Epoch 29/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0480 - mae: 0.0480 - val_loss: 0.0526 - val_mae: 0.0526\n",
            "Epoch 30/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0469 - mae: 0.0469 - val_loss: 0.0500 - val_mae: 0.0500\n",
            "Epoch 31/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0474 - mae: 0.0474 - val_loss: 0.0536 - val_mae: 0.0536\n",
            "Epoch 32/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0476 - mae: 0.0476 - val_loss: 0.0522 - val_mae: 0.0522\n",
            "Epoch 33/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0475 - mae: 0.0475 - val_loss: 0.0517 - val_mae: 0.0517\n",
            "Epoch 34/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0468 - mae: 0.0468 - val_loss: 0.0535 - val_mae: 0.0535\n",
            "Epoch 35/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0474 - mae: 0.0474 - val_loss: 0.0518 - val_mae: 0.0518\n",
            "Epoch 36/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0504 - val_mae: 0.0504\n",
            "Epoch 37/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0460 - mae: 0.0460 - val_loss: 0.0503 - val_mae: 0.0503\n",
            "Epoch 38/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0467 - mae: 0.0467 - val_loss: 0.0502 - val_mae: 0.0502\n",
            "Epoch 39/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0465 - mae: 0.0465 - val_loss: 0.0503 - val_mae: 0.0503\n",
            "Epoch 40/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0521 - val_mae: 0.0521\n",
            "Epoch 41/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0459 - mae: 0.0459 - val_loss: 0.0531 - val_mae: 0.0531\n",
            "Epoch 42/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 0.0458 - val_loss: 0.0513 - val_mae: 0.0513\n",
            "Epoch 43/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0465 - mae: 0.0465 - val_loss: 0.0509 - val_mae: 0.0509\n",
            "Epoch 44/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0466 - mae: 0.0466 - val_loss: 0.0505 - val_mae: 0.0505\n",
            "Epoch 45/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 0.0458 - val_loss: 0.0507 - val_mae: 0.0507\n",
            "Epoch 46/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0527 - val_mae: 0.0527\n",
            "Epoch 47/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0458 - mae: 0.0458 - val_loss: 0.0528 - val_mae: 0.0528\n",
            "Epoch 48/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0455 - mae: 0.0455 - val_loss: 0.0499 - val_mae: 0.0499\n",
            "Epoch 49/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0460 - mae: 0.0460 - val_loss: 0.0518 - val_mae: 0.0518\n",
            "Epoch 50/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0499 - val_mae: 0.0499\n",
            "Epoch 51/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0530 - val_mae: 0.0530\n",
            "Epoch 52/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0492 - val_mae: 0.0492\n",
            "Epoch 53/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0519 - val_mae: 0.0519\n",
            "Epoch 54/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0516 - val_mae: 0.0516\n",
            "Epoch 55/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0456 - mae: 0.0456 - val_loss: 0.0506 - val_mae: 0.0506\n",
            "Epoch 56/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0454 - mae: 0.0454 - val_loss: 0.0513 - val_mae: 0.0513\n",
            "Epoch 57/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0499 - val_mae: 0.0499\n",
            "Epoch 58/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0499 - val_mae: 0.0499\n",
            "Epoch 59/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0457 - mae: 0.0457 - val_loss: 0.0514 - val_mae: 0.0514\n",
            "Epoch 60/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0442 - mae: 0.0442 - val_loss: 0.0502 - val_mae: 0.0502\n",
            "Epoch 61/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0444 - mae: 0.0444 - val_loss: 0.0501 - val_mae: 0.0501\n",
            "Epoch 62/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0516 - val_mae: 0.0516\n",
            "Epoch 63/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0466 - val_mae: 0.0466\n",
            "Epoch 64/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0496 - val_mae: 0.0496\n",
            "Epoch 65/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0496 - val_mae: 0.0496\n",
            "Epoch 66/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0481 - val_mae: 0.0481\n",
            "Epoch 67/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0516 - val_mae: 0.0516\n",
            "Epoch 68/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0446 - mae: 0.0446 - val_loss: 0.0472 - val_mae: 0.0472\n",
            "Epoch 69/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0446 - mae: 0.0446 - val_loss: 0.0502 - val_mae: 0.0502\n",
            "Epoch 70/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0490 - val_mae: 0.0490\n",
            "Epoch 71/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0453 - mae: 0.0453 - val_loss: 0.0458 - val_mae: 0.0458\n",
            "Epoch 72/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0504 - val_mae: 0.0504\n",
            "Epoch 73/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0450 - mae: 0.0450 - val_loss: 0.0491 - val_mae: 0.0491\n",
            "Epoch 74/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0496 - val_mae: 0.0496\n",
            "Epoch 75/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0443 - mae: 0.0443 - val_loss: 0.0508 - val_mae: 0.0508\n",
            "Epoch 76/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0490 - val_mae: 0.0490\n",
            "Epoch 77/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0444 - mae: 0.0444 - val_loss: 0.0494 - val_mae: 0.0494\n",
            "Epoch 78/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0442 - mae: 0.0442 - val_loss: 0.0487 - val_mae: 0.0487\n",
            "Epoch 79/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0444 - mae: 0.0444 - val_loss: 0.0453 - val_mae: 0.0453\n",
            "Epoch 80/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0459 - val_mae: 0.0459\n",
            "Epoch 81/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0448 - mae: 0.0448 - val_loss: 0.0487 - val_mae: 0.0487\n",
            "Epoch 82/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0478 - val_mae: 0.0478\n",
            "Epoch 83/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0452 - mae: 0.0452 - val_loss: 0.0490 - val_mae: 0.0490\n",
            "Epoch 84/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0476 - val_mae: 0.0476\n",
            "Epoch 85/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0445 - mae: 0.0445 - val_loss: 0.0485 - val_mae: 0.0485\n",
            "Epoch 86/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.0491 - val_mae: 0.0491\n",
            "Epoch 87/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0446 - mae: 0.0446 - val_loss: 0.0487 - val_mae: 0.0487\n",
            "Epoch 88/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0485 - val_mae: 0.0485\n",
            "Epoch 89/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.0471 - val_mae: 0.0471\n",
            "Epoch 90/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 0.0444 - val_loss: 0.0480 - val_mae: 0.0480\n",
            "Epoch 91/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.0505 - val_mae: 0.0505\n",
            "Epoch 92/100\n",
            "56/56 [==============================] - 0s 5ms/step - loss: 0.0443 - mae: 0.0443 - val_loss: 0.0495 - val_mae: 0.0495\n",
            "Epoch 93/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0447 - mae: 0.0447 - val_loss: 0.0487 - val_mae: 0.0487\n",
            "Epoch 94/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0438 - mae: 0.0438 - val_loss: 0.0497 - val_mae: 0.0497\n",
            "Epoch 95/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0509 - val_mae: 0.0509\n",
            "Epoch 96/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0440 - mae: 0.0440 - val_loss: 0.0507 - val_mae: 0.0507\n",
            "Epoch 97/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0442 - mae: 0.0442 - val_loss: 0.0508 - val_mae: 0.0508\n",
            "Epoch 98/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0468 - val_mae: 0.0468\n",
            "Epoch 99/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0441 - mae: 0.0441 - val_loss: 0.0469 - val_mae: 0.0469\n",
            "Epoch 100/100\n",
            "56/56 [==============================] - 0s 4ms/step - loss: 0.0449 - mae: 0.0449 - val_loss: 0.0490 - val_mae: 0.0490\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZDRh1ZPuMT"
      },
      "source": [
        "## Performance Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gpn-fpWPuMU"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZMN3wA7PuMU",
        "outputId": "790efdd6-cffe-45df-8824-d23c93efd3c0"
      },
      "source": [
        "mean_absolute_error(y_pred,y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.37695768"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ST4HCccPuMU"
      },
      "source": [
        "LSTM results are compared with multi layer perceptron method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ3T9yagPuMU"
      },
      "source": [
        "from sklearn.neural_network import MLPRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5MoYupcPuMU"
      },
      "source": [
        "X_train, X_test = X_norm[:train_size], X_norm[train_size:]\n",
        "                \n",
        "y_train = y_norm[:train_size]\n",
        "y_true = y[train_size:]\n",
        "\n",
        "### MLP\n",
        "\n",
        "regressor = MLPRegressor(random_state=0,hidden_layer_sizes=(1,10))\n",
        "regressor.fit(X_train, y_train.ravel())\n",
        "\n",
        "y_pred = regressor.predict(X_test)\n",
        "y_pred = scaler_y.inverse_transform(y_pred.reshape(y_pred.shape[0],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D983rfgTPuMV",
        "outputId": "1cffa68d-06b4-46ce-eeb1-0d4c7008a9fa"
      },
      "source": [
        "mean_absolute_error(y_pred,y_true)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5375156040616599"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95YmWYOOPuMV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}