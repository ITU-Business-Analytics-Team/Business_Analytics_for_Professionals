{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITU-Business-Analytics-Team/Business_Analytics_for_Professionals/blob/main/Part%20I%20%3A%20Methods%20%26%20Technologies%20for%20Business%20Analytics/Chapter%207%3A%20Text%20Analytics/7_6_3_Deep_Learning_Based_Sentiment_Analysis_Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4lSXtbOfG0g"
      },
      "source": [
        "# **Sentiment Analysis (Opinion Mining)**\n",
        "## Deep Learning Based Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRtKNEZ-fG0k"
      },
      "source": [
        "### FLAIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU9StgmgfG0l"
      },
      "source": [
        "Flair is developed by Facebook and is a deep learning based text classifier as Bert and XLNet. First, we start with installation of necessary libraries to implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LaDJgZmE1rd-",
        "outputId": "fd700bcf-6dda-44c2-9cfe-201882a0bee3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.9)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.4.1)\n",
            "Requirement already satisfied: more-itertools~=8.8.0 in /usr/local/lib/python3.7/dist-packages (from flair) (8.8.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.3)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.0.3)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.7/dist-packages (from flair) (0.5.4)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.13)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair) (3.12.2)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.12.3)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.9.0+cu111)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.3)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.26.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.19.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.6.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.0.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.0.46)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied: allennlp==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.19.12)\n",
            "Requirement already satisfied: sqlparse>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.4.2)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.5.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.1.0)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.6.2)\n",
            "Requirement already satisfied: pytorch-transformers==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.1.0)\n",
            "Collecting conllu==1.3.1\n",
            "  Using cached conllu-1.3.1-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: flask-cors>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.0.10)\n",
            "Requirement already satisfied: flaky in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.7.0)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2.0.0)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.4.1)\n",
            "Requirement already satisfied: responses>=0.7 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.22.2.post1)\n",
            "Requirement already satisfied: gevent>=1.3.6 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (21.8.0)\n",
            "Requirement already satisfied: spacy<2.2,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2.1.9)\n",
            "Requirement already satisfied: parsimonious>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.8.1)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (4.62.3)\n",
            "Requirement already satisfied: jsonnet>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (0.17.0)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.3.2)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (6.0.3)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2.4)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2.26.0)\n",
            "Requirement already satisfied: overrides in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.1.0)\n",
            "Requirement already satisfied: numpydoc>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (2018.9)\n",
            "Requirement already satisfied: flask>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.1.4)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.2.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.19.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (3.2.5)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from allennlp==0.9.0) (1.9.0+cu111)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.1.0->allennlp==0.9.0) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers==1.1.0->allennlp==0.9.0) (0.1.95)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=1.0.2->allennlp==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors>=3.0.7->allennlp==0.9.0) (1.15.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (5.4.0)\n",
            "Requirement already satisfied: greenlet<2.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (1.1.2)\n",
            "Requirement already satisfied: zope.event in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (4.5.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from gevent>=1.3.6->allennlp==0.9.0) (57.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=1.0.2->allennlp==0.9.0) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->allennlp==0.9.0) (1.3.2)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.7/dist-packages (from numpydoc>=0.8.0->allennlp==0.9.0) (1.8.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (2.0.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp==0.9.0) (2021.5.30)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (7.0.8)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (0.8.2)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (2.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (0.2.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (0.9.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (2.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.2,>=2.1.0->allennlp==0.9.0) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (1.2.4)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (2.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (2.9.1)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (1.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (21.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (0.7.12)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (0.17.1)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (2.6.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX>=1.2->allennlp==0.9.0) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2.0->allennlp==0.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0) (0.5.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0) (0.10.0)\n",
            "Requirement already satisfied: botocore<1.23.0,>=1.22.12 in /usr/local/lib/python3.7/dist-packages (from boto3->allennlp==0.9.0) (1.22.12)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->allennlp==0.9.0) (0.2.5)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp==0.9.0) (1.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonpickle->allennlp==0.9.0) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonpickle->allennlp==0.9.0) (3.6.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (1.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (21.2.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (8.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp==0.9.0) (0.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp==0.9.0) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0) (1.1.5)\n",
            "Installing collected packages: conllu\n",
            "  Attempting uninstall: conllu\n",
            "    Found existing installation: conllu 4.4.1\n",
            "    Uninstalling conllu-4.4.1:\n",
            "      Successfully uninstalled conllu-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flair 0.9 requires conllu>=4.0, but you have conllu 1.3.1 which is incompatible.\u001b[0m\n",
            "Successfully installed conllu-1.3.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "conllu"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install flair\n",
        "!pip install allennlp==0.9.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n3HSA2AS0e3c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0l52ccPfG0n"
      },
      "source": [
        "Flair comes with its own dataset format. In order to use it correctly, data should be labelled as __ label__x where x represents the class. Therefore, the train and test datasets are reformatted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LZ3msJkV0-7J",
        "outputId": "5966e847-c91b-4db8-cc0b-d85831ccc7b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>nickel jumps on talks of indonesia export ban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>hanghai copper hits near 2-week high on trade ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__label__0</td>\n",
              "      <td>copper at near 2-week highs on hopes china imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>china's yunnan to help firms stockpile 110,000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>rpt-update 1-china turns net aluminium importe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1115</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>copper rebounds as u.s.-mexico deal calms nerves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1116</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>china demand hopes help aluminium to hold near...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1117</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>rpt-column-new contracts, new platform as lme ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1118</th>\n",
              "      <td>__label__-1</td>\n",
              "      <td>rpt-column- china's aluminium import surge a s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1119</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>column-metal markets caught out by strength of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1120 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            label                                               text\n",
              "0      __label__1      nickel jumps on talks of indonesia export ban\n",
              "1      __label__1  hanghai copper hits near 2-week high on trade ...\n",
              "2      __label__0  copper at near 2-week highs on hopes china imp...\n",
              "3      __label__1  china's yunnan to help firms stockpile 110,000...\n",
              "4      __label__1  rpt-update 1-china turns net aluminium importe...\n",
              "...           ...                                                ...\n",
              "1115   __label__1   copper rebounds as u.s.-mexico deal calms nerves\n",
              "1116   __label__1  china demand hopes help aluminium to hold near...\n",
              "1117   __label__1  rpt-column-new contracts, new platform as lme ...\n",
              "1118  __label__-1  rpt-column- china's aluminium import surge a s...\n",
              "1119   __label__1  column-metal markets caught out by strength of...\n",
              "\n",
              "[1120 rows x 2 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url=   'https://docs.google.com/spreadsheets/d/1XXyxrd7r0mx7kyLaYHDVwh6BFJzo8cPD/edit?usp=sharing&ouid=108589602591644119588&rtpof=true&sd=true'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "\n",
        "df = pd.read_excel(path)\n",
        "df['summary'] = df['summary'].map(lambda x: x.lstrip('News :'))\n",
        "df['summary'] = df['summary'].map(lambda x: x.lstrip('UPDATE'))\n",
        "df['summary'] = df['summary'].map(lambda x: x.lstrip('METALS-'))\n",
        "df.rename(columns={'sentiment':'score', 'summary':'text'}, inplace = True)\n",
        "# Optional lowercase for test data (if model was trained on lowercased text)\n",
        "df['text'] = df['text'].str.lower()\n",
        "df['label'] = '__label__' + df['score'].astype(str)\n",
        "cols = df.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df = df[cols]\n",
        "df = df.drop(columns='score')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mAznL2_LkwRS",
        "outputId": "aaa27fb0-21c1-45e6-9a9e-8c271e72ea2e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__label__0</td>\n",
              "      <td>copper at near 2-week highs on hopes china imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>china's yunnan to help firms stockpile 110,000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__label__-1</td>\n",
              "      <td>column-politics trumps aluminium as u.s. reimp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__label__-1</td>\n",
              "      <td>base metals decline on weak china demand outlook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__label__-1</td>\n",
              "      <td>aluminium  falls to $1,751.50/t, lowest since...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>china names former chinalco exec as industry m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>__label__0</td>\n",
              "      <td>copper edges off two-year low as washington so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>__label__-1</td>\n",
              "      <td>uncertainty on global growth, trade war weighs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>copper gains after fed chief rekindles rate cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>column-metal markets caught out by strength of...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>168 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           label                                               text\n",
              "0     __label__0  copper at near 2-week highs on hopes china imp...\n",
              "1     __label__1  china's yunnan to help firms stockpile 110,000...\n",
              "2    __label__-1  column-politics trumps aluminium as u.s. reimp...\n",
              "3    __label__-1   base metals decline on weak china demand outlook\n",
              "4    __label__-1   aluminium  falls to $1,751.50/t, lowest since...\n",
              "..           ...                                                ...\n",
              "163   __label__1  china names former chinalco exec as industry m...\n",
              "164   __label__0  copper edges off two-year low as washington so...\n",
              "165  __label__-1  uncertainty on global growth, trade war weighs...\n",
              "166   __label__1  copper gains after fed chief rekindles rate cu...\n",
              "167   __label__1  column-metal markets caught out by strength of...\n",
              "\n",
              "[168 rows x 2 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "url=   'https://docs.google.com/spreadsheets/d/145tqf2J949KGCYnH-Nx3hiaHTogiZFn4/edit?usp=sharing&ouid=108589602591644119588&rtpof=true&sd=true'\n",
        "path = 'https://drive.google.com/uc?export=download&id='+url.split('/')[-2]\n",
        "test_df = pd.read_excel(path)\n",
        "test_df['summary'] = test_df['summary'].map(lambda x: x.lstrip('News :'))\n",
        "test_df['summary'] = test_df['summary'].map(lambda x: x.lstrip('UPDATE'))\n",
        "test_df['summary'] = test_df['summary'].map(lambda x: x.lstrip('METALS-'))\n",
        "test_df.rename(columns={'sentiment':'score', 'summary':'text'}, inplace = True)\n",
        "test_df['text'] = test_df['text'].str.lower()\n",
        "test_df['label'] = '__label__' + test_df['score'].astype(str)\n",
        "cols = test_df.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "test_df = test_df[cols]\n",
        "test_df = test_df.drop(columns='score')\n",
        "test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QuNy2Ox2mja0"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates().merge(test_df.drop_duplicates(), on=test_df.columns.to_list(), \n",
        "                   how='left', indicator=True, right_index = False, left_index = False)\n",
        "df = df.loc[df._merge=='left_only',df.columns!='_merge']\n",
        "df = df.reset_index(drop = True, inplace= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nKFKuYHPmrGW",
        "outputId": "0291b03b-958d-4c8b-957e-53b6d0d6188e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>nickel jumps on talks of indonesia export ban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>hanghai copper hits near 2-week high on trade ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>rpt-update 1-china turns net aluminium importe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>__label__-1</td>\n",
              "      <td>1-china july aluminium output hits record ami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>copper edges to 11-week high on china recovery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>rpt-column-pain for aluminium shorts as lme ge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>copper rebounds as u.s.-mexico deal calms nerves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>china demand hopes help aluminium to hold near...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>914</th>\n",
              "      <td>__label__1</td>\n",
              "      <td>rpt-column-new contracts, new platform as lme ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>__label__-1</td>\n",
              "      <td>rpt-column- china's aluminium import surge a s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>916 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           label                                               text\n",
              "0     __label__1      nickel jumps on talks of indonesia export ban\n",
              "1     __label__1  hanghai copper hits near 2-week high on trade ...\n",
              "2     __label__1  rpt-update 1-china turns net aluminium importe...\n",
              "3    __label__-1   1-china july aluminium output hits record ami...\n",
              "4     __label__1     copper edges to 11-week high on china recovery\n",
              "..           ...                                                ...\n",
              "911   __label__1  rpt-column-pain for aluminium shorts as lme ge...\n",
              "912   __label__1   copper rebounds as u.s.-mexico deal calms nerves\n",
              "913   __label__1  china demand hopes help aluminium to hold near...\n",
              "914   __label__1  rpt-column-new contracts, new platform as lme ...\n",
              "915  __label__-1  rpt-column- china's aluminium import surge a s...\n",
              "\n",
              "[916 rows x 2 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbd5uInOfG0r"
      },
      "source": [
        "After reformatting and merging, the train dataset is splitted as 90% of it becomes validation dataset to use understand the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "O-qf7iV8khTp"
      },
      "outputs": [],
      "source": [
        "df.iloc[0:int(len(df)*0.9)].to_csv('train.csv', sep='\\t', index = False, header = False)\n",
        "df.iloc[int(len(df)*0.9):].to_csv('dev.csv', sep='\\t', index = False, header = False)\n",
        "test_df.to_csv('test.csv', sep='\\t', index = False, header = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LjKM97mfG0s"
      },
      "source": [
        "Flair works with txt files, so we need to convert .csv files to .txt. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GZMg1OB5fG0s"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "def csv_to_txt(filename):\n",
        "    csv_file = filename+'.csv'\n",
        "    txt_file = filename+'.txt'\n",
        "    with open(txt_file, \"w\") as my_output_file:\n",
        "        with open(csv_file, \"r\") as my_input_file:\n",
        "            [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
        "        my_output_file.close()\n",
        "\n",
        "        \n",
        "files = ['train', 'dev', 'test']\n",
        "for file in files:\n",
        "    csv_to_txt(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOTcpQ7ufG0s"
      },
      "source": [
        "Flair will create a classification corpus with the files that are prepared in previous cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "04oAUQyal7xd",
        "outputId": "172e7113-9c9f-4ee6-d611-342a936460dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.7/dist-packages (0.9)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.12.3)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair) (1.5.10)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.7.0)\n",
            "Requirement already satisfied: more-itertools~=8.8.0 in /usr/local/lib/python3.7/dist-packages (from flair) (8.8.0)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.95)\n",
            "Collecting conllu>=4.0\n",
            "  Using cached conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.2)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.62.3)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair) (0.4.1)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair) (6.0.3)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.7/dist-packages (from flair) (0.5.4)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.6.5)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair) (1.2.13)\n",
            "Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair) (3.12.2)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair) (1.0.9)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.9.0+cu111)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (2.26.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair) (3.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (1.19.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.2.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.6.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair) (3.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.6.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2021.5.30)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (2.0.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (0.0.46)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (21.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Installing collected packages: conllu\n",
            "  Attempting uninstall: conllu\n",
            "    Found existing installation: conllu 1.3.1\n",
            "    Uninstalling conllu-1.3.1:\n",
            "      Successfully uninstalled conllu-1.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "allennlp 0.9.0 requires conllu==1.3.1, but you have conllu 4.4.1 which is incompatible.\u001b[0m\n",
            "Successfully installed conllu-4.4.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "conllu"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NX16UmIrkNXy",
        "outputId": "89312480-a575-4128-ae44-efe0b89a1c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-11-07 09:46:28,693 Reading data from /content\n",
            "2021-11-07 09:46:28,695 Train: /content/train.txt\n",
            "2021-11-07 09:46:28,698 Dev: /content/dev.txt\n",
            "2021-11-07 09:46:28,701 Test: /content/test.txt\n",
            "2021-11-07 09:46:28,724 Initialized corpus /content/ (label type name is 'class')\n",
            "824\n",
            "168\n",
            "92\n"
          ]
        }
      ],
      "source": [
        "from flair.data_fetcher import NLPTaskDataFetcher\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentLSTMEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from pathlib import Path\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ClassificationCorpus\n",
        "from flair.embeddings import TransformerDocumentEmbeddings,TransformerWordEmbeddings\n",
        "from flair.embeddings import BertEmbeddings, ELMoEmbeddings\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = '/content/'\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ClassificationCorpus(data_folder,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')\n",
        "# print the number of Sentences in the train split\n",
        "print(len(corpus.train))\n",
        "\n",
        "# print the number of Sentences in the test split\n",
        "print(len(corpus.test))\n",
        "\n",
        "# print the number of Sentences in the dev split\n",
        "print(len(corpus.dev))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoYdJIf0fG0t"
      },
      "source": [
        "Several embeddings can be used in Flair, which is one of the most strong aspects of it. Since transformers architecture success in the problem is approved above, we will continue with that. Additional options for embedding are given in comment out. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GZ_vqYRelsmM"
      },
      "outputs": [],
      "source": [
        "from flair.embeddings import StackedEmbeddings\n",
        "\n",
        "#init BERT base (cases)\n",
        "#optional_embedding = BertEmbeddings('bert-base-uncased')\n",
        "# OR init ELMo (original)\n",
        "#optional_embedding = ELMoEmbeddings('original')\n",
        "\n",
        "#word_embeddings = [\n",
        " #   optional_embedding,\n",
        " #   FlairEmbeddings('news-forward'),\n",
        " #   FlairEmbeddings('news-backward')]\n",
        "\n",
        "\n",
        "#word_embeddings = [WordEmbeddings('glove')]\n",
        "\n",
        "#document_embeddings = DocumentRNNEmbeddings(\n",
        "#        word_embeddings,\n",
        "#        hidden_size=512,\n",
        "#        reproject_words=True,\n",
        "#        reproject_words_dimension=256\n",
        "#    )\n",
        "\n",
        "document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased',fine_tune=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MahJalrFfG0u"
      },
      "source": [
        "Now, Flair build the text classifier with chosen embeddings and created corpus. Since there are 3 classes, multi label is set true."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtH4nGnZteOk",
        "outputId": "9a66b5ae-581c-4233-ea6a-8b2a5a3d035b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-11-07 09:24:53,770 Reading data from /content\n",
            "2021-11-07 09:24:53,773 Train: /content/train.csv\n",
            "2021-11-07 09:24:53,775 Dev: /content/dev.txt\n",
            "2021-11-07 09:24:53,778 Test: /content/test.txt\n",
            "2021-11-07 09:24:53,821 Initialized corpus /content/ (label type name is 'topic')\n",
            "2021-11-07 09:24:53,824 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|██████████| 824/824 [00:00<00:00, 995.03it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-11-07 09:24:54,895 Corpus contains the labels: topic (#824)\n",
            "2021-11-07 09:24:54,899 Created (for label 'topic') Dictionary with 3 tags: 1, -1, 0\n",
            "2021-11-07 09:24:54,905 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:24:54,909 Model: \"TextClassifier(\n",
            "  (loss_function): BCEWithLogitsLoss()\n",
            "  (document_embeddings): TransformerDocumentEmbeddings(\n",
            "    (model): DistilBertModel(\n",
            "      (embeddings): Embeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (transformer): Transformer(\n",
            "        (layer): ModuleList(\n",
            "          (0): TransformerBlock(\n",
            "            (attention): MultiHeadSelfAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          )\n",
            "          (1): TransformerBlock(\n",
            "            (attention): MultiHeadSelfAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          )\n",
            "          (2): TransformerBlock(\n",
            "            (attention): MultiHeadSelfAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          )\n",
            "          (3): TransformerBlock(\n",
            "            (attention): MultiHeadSelfAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          )\n",
            "          (4): TransformerBlock(\n",
            "            (attention): MultiHeadSelfAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          )\n",
            "          (5): TransformerBlock(\n",
            "            (attention): MultiHeadSelfAttention(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): Linear(in_features=768, out_features=3, bias=True)\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2021-11-07 09:24:54,911 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:24:54,913 Corpus: \"Corpus: 824 train + 92 dev + 168 test sentences\"\n",
            "2021-11-07 09:24:54,914 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:24:54,916 Parameters:\n",
            "2021-11-07 09:24:54,917  - learning_rate: \"0.1\"\n",
            "2021-11-07 09:24:54,918  - mini_batch_size: \"32\"\n",
            "2021-11-07 09:24:54,920  - patience: \"3\"\n",
            "2021-11-07 09:24:54,922  - anneal_factor: \"0.5\"\n",
            "2021-11-07 09:24:54,923  - max_epochs: \"10\"\n",
            "2021-11-07 09:24:54,924  - shuffle: \"True\"\n",
            "2021-11-07 09:24:54,926  - train_with_dev: \"False\"\n",
            "2021-11-07 09:24:54,928  - batch_growth_annealing: \"False\"\n",
            "2021-11-07 09:24:54,929 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:24:54,930 Model training base path: \".\"\n",
            "2021-11-07 09:24:54,932 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:24:54,933 Device: cpu\n",
            "2021-11-07 09:24:54,935 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:24:54,936 Embeddings storage mode: cpu\n",
            "2021-11-07 09:24:54,940 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-11-07 09:25:03,061 epoch 1 - iter 2/26 - loss 0.02481312 - samples/sec: 8.13 - lr: 0.100000\n",
            "2021-11-07 09:25:10,633 epoch 1 - iter 4/26 - loss 0.02223014 - samples/sec: 8.48 - lr: 0.100000\n",
            "2021-11-07 09:25:21,659 epoch 1 - iter 6/26 - loss 0.02024161 - samples/sec: 5.81 - lr: 0.100000\n",
            "2021-11-07 09:25:32,838 epoch 1 - iter 8/26 - loss 0.02060364 - samples/sec: 5.73 - lr: 0.100000\n",
            "2021-11-07 09:25:42,312 epoch 1 - iter 10/26 - loss 0.01990936 - samples/sec: 6.76 - lr: 0.100000\n",
            "2021-11-07 09:25:52,842 epoch 1 - iter 12/26 - loss 0.01920096 - samples/sec: 6.08 - lr: 0.100000\n",
            "2021-11-07 09:26:01,079 epoch 1 - iter 14/26 - loss 0.01889305 - samples/sec: 7.77 - lr: 0.100000\n",
            "2021-11-07 09:26:10,720 epoch 1 - iter 16/26 - loss 0.01869085 - samples/sec: 6.64 - lr: 0.100000\n",
            "2021-11-07 09:26:18,001 epoch 1 - iter 18/26 - loss 0.01849717 - samples/sec: 8.81 - lr: 0.100000\n",
            "2021-11-07 09:26:25,409 epoch 1 - iter 20/26 - loss 0.01843454 - samples/sec: 8.64 - lr: 0.100000\n",
            "2021-11-07 09:26:33,232 epoch 1 - iter 22/26 - loss 0.01841508 - samples/sec: 8.18 - lr: 0.100000\n",
            "2021-11-07 09:26:43,240 epoch 1 - iter 24/26 - loss 0.01846056 - samples/sec: 6.40 - lr: 0.100000\n",
            "2021-11-07 09:26:56,405 epoch 1 - iter 26/26 - loss 0.01862970 - samples/sec: 4.86 - lr: 0.100000\n",
            "2021-11-07 09:26:56,505 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:26:56,510 EPOCH 1 done: loss 0.0186 - lr 0.1000000\n",
            "2021-11-07 09:27:01,500 DEV : loss 0.01730850525200367 - f1-score (micro avg)  0.5746\n",
            "2021-11-07 09:27:01,553 BAD EPOCHS (no improvement): 0\n",
            "2021-11-07 09:27:01,559 saving best model\n",
            "2021-11-07 09:27:02,112 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:27:13,278 epoch 2 - iter 2/26 - loss 0.01709885 - samples/sec: 5.86 - lr: 0.100000\n",
            "2021-11-07 09:27:21,824 epoch 2 - iter 4/26 - loss 0.01623688 - samples/sec: 7.50 - lr: 0.100000\n",
            "2021-11-07 09:27:31,830 epoch 2 - iter 6/26 - loss 0.01651865 - samples/sec: 6.41 - lr: 0.100000\n",
            "2021-11-07 09:27:38,697 epoch 2 - iter 8/26 - loss 0.01665252 - samples/sec: 9.32 - lr: 0.100000\n",
            "2021-11-07 09:27:47,692 epoch 2 - iter 10/26 - loss 0.01698158 - samples/sec: 7.12 - lr: 0.100000\n",
            "2021-11-07 09:27:54,530 epoch 2 - iter 12/26 - loss 0.01708873 - samples/sec: 9.38 - lr: 0.100000\n",
            "2021-11-07 09:28:01,889 epoch 2 - iter 14/26 - loss 0.01697577 - samples/sec: 8.70 - lr: 0.100000\n",
            "2021-11-07 09:28:13,183 epoch 2 - iter 16/26 - loss 0.01694471 - samples/sec: 5.67 - lr: 0.100000\n",
            "2021-11-07 09:28:24,974 epoch 2 - iter 18/26 - loss 0.01700703 - samples/sec: 5.43 - lr: 0.100000\n",
            "2021-11-07 09:28:33,523 epoch 2 - iter 20/26 - loss 0.01708822 - samples/sec: 7.49 - lr: 0.100000\n",
            "2021-11-07 09:28:42,332 epoch 2 - iter 22/26 - loss 0.01707756 - samples/sec: 7.27 - lr: 0.100000\n",
            "2021-11-07 09:28:54,844 epoch 2 - iter 24/26 - loss 0.01709819 - samples/sec: 5.12 - lr: 0.100000\n",
            "2021-11-07 09:29:03,789 epoch 2 - iter 26/26 - loss 0.01723632 - samples/sec: 7.16 - lr: 0.100000\n",
            "2021-11-07 09:29:03,945 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:29:03,947 EPOCH 2 done: loss 0.0172 - lr 0.1000000\n",
            "2021-11-07 09:29:08,164 DEV : loss 0.016959620639681816 - f1-score (micro avg)  0.5976\n",
            "2021-11-07 09:29:08,213 BAD EPOCHS (no improvement): 0\n",
            "2021-11-07 09:29:08,215 saving best model\n",
            "2021-11-07 09:29:08,816 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:29:17,068 epoch 3 - iter 2/26 - loss 0.01548880 - samples/sec: 7.99 - lr: 0.100000\n",
            "2021-11-07 09:29:27,196 epoch 3 - iter 4/26 - loss 0.01651779 - samples/sec: 6.34 - lr: 0.100000\n",
            "2021-11-07 09:29:34,534 epoch 3 - iter 6/26 - loss 0.01629629 - samples/sec: 8.73 - lr: 0.100000\n",
            "2021-11-07 09:29:45,894 epoch 3 - iter 8/26 - loss 0.01653544 - samples/sec: 5.64 - lr: 0.100000\n",
            "2021-11-07 09:29:54,182 epoch 3 - iter 10/26 - loss 0.01702376 - samples/sec: 7.74 - lr: 0.100000\n",
            "2021-11-07 09:30:02,345 epoch 3 - iter 12/26 - loss 0.01699984 - samples/sec: 7.85 - lr: 0.100000\n",
            "2021-11-07 09:30:14,490 epoch 3 - iter 14/26 - loss 0.01692276 - samples/sec: 5.27 - lr: 0.100000\n",
            "2021-11-07 09:30:23,619 epoch 3 - iter 16/26 - loss 0.01681695 - samples/sec: 7.01 - lr: 0.100000\n",
            "2021-11-07 09:30:30,628 epoch 3 - iter 18/26 - loss 0.01666394 - samples/sec: 9.14 - lr: 0.100000\n",
            "2021-11-07 09:30:42,351 epoch 3 - iter 20/26 - loss 0.01659334 - samples/sec: 5.47 - lr: 0.100000\n",
            "2021-11-07 09:30:51,186 epoch 3 - iter 22/26 - loss 0.01646831 - samples/sec: 7.25 - lr: 0.100000\n",
            "2021-11-07 09:30:59,515 epoch 3 - iter 24/26 - loss 0.01629376 - samples/sec: 7.69 - lr: 0.100000\n",
            "2021-11-07 09:31:11,244 epoch 3 - iter 26/26 - loss 0.01666830 - samples/sec: 5.46 - lr: 0.100000\n",
            "2021-11-07 09:31:11,399 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:31:11,401 EPOCH 3 done: loss 0.0167 - lr 0.1000000\n",
            "2021-11-07 09:31:15,615 DEV : loss 0.016209252178668976 - f1-score (micro avg)  0.5241\n",
            "2021-11-07 09:31:15,665 BAD EPOCHS (no improvement): 1\n",
            "2021-11-07 09:31:15,667 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:31:26,307 epoch 4 - iter 2/26 - loss 0.01644070 - samples/sec: 6.16 - lr: 0.100000\n",
            "2021-11-07 09:31:37,402 epoch 4 - iter 4/26 - loss 0.01571890 - samples/sec: 5.77 - lr: 0.100000\n",
            "2021-11-07 09:31:45,611 epoch 4 - iter 6/26 - loss 0.01522409 - samples/sec: 7.82 - lr: 0.100000\n",
            "2021-11-07 09:31:58,314 epoch 4 - iter 8/26 - loss 0.01512770 - samples/sec: 5.04 - lr: 0.100000\n",
            "2021-11-07 09:32:08,097 epoch 4 - iter 10/26 - loss 0.01512764 - samples/sec: 6.55 - lr: 0.100000\n",
            "2021-11-07 09:32:17,674 epoch 4 - iter 12/26 - loss 0.01494894 - samples/sec: 6.69 - lr: 0.100000\n",
            "2021-11-07 09:32:24,802 epoch 4 - iter 14/26 - loss 0.01508005 - samples/sec: 8.99 - lr: 0.100000\n",
            "2021-11-07 09:32:32,751 epoch 4 - iter 16/26 - loss 0.01506377 - samples/sec: 8.05 - lr: 0.100000\n",
            "2021-11-07 09:32:43,198 epoch 4 - iter 18/26 - loss 0.01520046 - samples/sec: 6.13 - lr: 0.100000\n",
            "2021-11-07 09:32:50,577 epoch 4 - iter 20/26 - loss 0.01501200 - samples/sec: 8.68 - lr: 0.100000\n",
            "2021-11-07 09:33:00,010 epoch 4 - iter 22/26 - loss 0.01479461 - samples/sec: 6.79 - lr: 0.100000\n",
            "2021-11-07 09:33:08,515 epoch 4 - iter 24/26 - loss 0.01459344 - samples/sec: 7.53 - lr: 0.100000\n",
            "2021-11-07 09:33:15,338 epoch 4 - iter 26/26 - loss 0.01468841 - samples/sec: 9.38 - lr: 0.100000\n",
            "2021-11-07 09:33:15,493 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:33:15,495 EPOCH 4 done: loss 0.0147 - lr 0.1000000\n",
            "2021-11-07 09:33:19,699 DEV : loss 0.013464448042213917 - f1-score (micro avg)  0.7345\n",
            "2021-11-07 09:33:19,752 BAD EPOCHS (no improvement): 0\n",
            "2021-11-07 09:33:19,754 saving best model\n",
            "2021-11-07 09:33:20,368 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:33:30,488 epoch 5 - iter 2/26 - loss 0.01186712 - samples/sec: 6.49 - lr: 0.100000\n",
            "2021-11-07 09:33:38,661 epoch 5 - iter 4/26 - loss 0.01254569 - samples/sec: 7.84 - lr: 0.100000\n",
            "2021-11-07 09:33:46,804 epoch 5 - iter 6/26 - loss 0.01211557 - samples/sec: 7.88 - lr: 0.100000\n",
            "2021-11-07 09:33:55,096 epoch 5 - iter 8/26 - loss 0.01265615 - samples/sec: 7.73 - lr: 0.100000\n",
            "2021-11-07 09:34:03,230 epoch 5 - iter 10/26 - loss 0.01299531 - samples/sec: 7.87 - lr: 0.100000\n",
            "2021-11-07 09:34:14,714 epoch 5 - iter 12/26 - loss 0.01308307 - samples/sec: 5.57 - lr: 0.100000\n",
            "2021-11-07 09:34:24,922 epoch 5 - iter 14/26 - loss 0.01276409 - samples/sec: 6.29 - lr: 0.100000\n",
            "2021-11-07 09:34:36,414 epoch 5 - iter 16/26 - loss 0.01272656 - samples/sec: 5.57 - lr: 0.100000\n",
            "2021-11-07 09:34:51,391 epoch 5 - iter 18/26 - loss 0.01269663 - samples/sec: 4.27 - lr: 0.100000\n",
            "2021-11-07 09:34:58,932 epoch 5 - iter 20/26 - loss 0.01289232 - samples/sec: 8.49 - lr: 0.100000\n",
            "2021-11-07 09:35:07,883 epoch 5 - iter 22/26 - loss 0.01267803 - samples/sec: 7.15 - lr: 0.100000\n",
            "2021-11-07 09:35:14,814 epoch 5 - iter 24/26 - loss 0.01272169 - samples/sec: 9.24 - lr: 0.100000\n",
            "2021-11-07 09:35:21,421 epoch 5 - iter 26/26 - loss 0.01315364 - samples/sec: 9.69 - lr: 0.100000\n",
            "2021-11-07 09:35:21,579 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:35:21,582 EPOCH 5 done: loss 0.0132 - lr 0.1000000\n",
            "2021-11-07 09:35:25,772 DEV : loss 0.01421865914016962 - f1-score (micro avg)  0.7073\n",
            "2021-11-07 09:35:25,823 BAD EPOCHS (no improvement): 1\n",
            "2021-11-07 09:35:25,828 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:35:35,711 epoch 6 - iter 2/26 - loss 0.01159500 - samples/sec: 6.65 - lr: 0.100000\n",
            "2021-11-07 09:35:49,968 epoch 6 - iter 4/26 - loss 0.01252440 - samples/sec: 4.63 - lr: 0.100000\n",
            "2021-11-07 09:35:59,642 epoch 6 - iter 6/26 - loss 0.01342007 - samples/sec: 6.62 - lr: 0.100000\n",
            "2021-11-07 09:36:09,804 epoch 6 - iter 8/26 - loss 0.01254635 - samples/sec: 6.30 - lr: 0.100000\n",
            "2021-11-07 09:36:19,392 epoch 6 - iter 10/26 - loss 0.01174903 - samples/sec: 6.68 - lr: 0.100000\n",
            "2021-11-07 09:36:28,422 epoch 6 - iter 12/26 - loss 0.01142387 - samples/sec: 7.10 - lr: 0.100000\n",
            "2021-11-07 09:36:36,266 epoch 6 - iter 14/26 - loss 0.01177219 - samples/sec: 8.16 - lr: 0.100000\n",
            "2021-11-07 09:36:47,591 epoch 6 - iter 16/26 - loss 0.01217401 - samples/sec: 5.65 - lr: 0.100000\n",
            "2021-11-07 09:36:58,418 epoch 6 - iter 18/26 - loss 0.01266975 - samples/sec: 5.92 - lr: 0.100000\n",
            "2021-11-07 09:37:06,769 epoch 6 - iter 20/26 - loss 0.01251723 - samples/sec: 7.67 - lr: 0.100000\n",
            "2021-11-07 09:37:14,345 epoch 6 - iter 22/26 - loss 0.01246722 - samples/sec: 8.45 - lr: 0.100000\n",
            "2021-11-07 09:37:21,494 epoch 6 - iter 24/26 - loss 0.01227670 - samples/sec: 8.96 - lr: 0.100000\n",
            "2021-11-07 09:37:28,536 epoch 6 - iter 26/26 - loss 0.01229828 - samples/sec: 9.09 - lr: 0.100000\n",
            "2021-11-07 09:37:28,702 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:37:28,703 EPOCH 6 done: loss 0.0123 - lr 0.1000000\n",
            "2021-11-07 09:37:32,923 DEV : loss 0.014033462852239609 - f1-score (micro avg)  0.7735\n",
            "2021-11-07 09:37:32,975 BAD EPOCHS (no improvement): 0\n",
            "2021-11-07 09:37:32,979 saving best model\n",
            "2021-11-07 09:37:34,207 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:37:42,539 epoch 7 - iter 2/26 - loss 0.00875519 - samples/sec: 7.95 - lr: 0.100000\n",
            "2021-11-07 09:37:49,486 epoch 7 - iter 4/26 - loss 0.00899761 - samples/sec: 9.23 - lr: 0.100000\n",
            "2021-11-07 09:37:57,535 epoch 7 - iter 6/26 - loss 0.00931285 - samples/sec: 7.96 - lr: 0.100000\n",
            "2021-11-07 09:38:06,234 epoch 7 - iter 8/26 - loss 0.00933774 - samples/sec: 7.36 - lr: 0.100000\n",
            "2021-11-07 09:38:14,927 epoch 7 - iter 10/26 - loss 0.00981877 - samples/sec: 7.37 - lr: 0.100000\n",
            "2021-11-07 09:38:27,982 epoch 7 - iter 12/26 - loss 0.00955396 - samples/sec: 4.91 - lr: 0.100000\n",
            "2021-11-07 09:38:36,174 epoch 7 - iter 14/26 - loss 0.01007848 - samples/sec: 7.82 - lr: 0.100000\n",
            "2021-11-07 09:38:48,920 epoch 7 - iter 16/26 - loss 0.01030675 - samples/sec: 5.02 - lr: 0.100000\n",
            "2021-11-07 09:38:57,589 epoch 7 - iter 18/26 - loss 0.01037677 - samples/sec: 7.39 - lr: 0.100000\n",
            "2021-11-07 09:39:08,820 epoch 7 - iter 20/26 - loss 0.01023262 - samples/sec: 5.70 - lr: 0.100000\n",
            "2021-11-07 09:39:21,544 epoch 7 - iter 22/26 - loss 0.01064137 - samples/sec: 5.03 - lr: 0.100000\n",
            "2021-11-07 09:39:29,615 epoch 7 - iter 24/26 - loss 0.01074838 - samples/sec: 7.93 - lr: 0.100000\n",
            "2021-11-07 09:39:36,395 epoch 7 - iter 26/26 - loss 0.01087161 - samples/sec: 9.45 - lr: 0.100000\n",
            "2021-11-07 09:39:36,551 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:39:36,553 EPOCH 7 done: loss 0.0109 - lr 0.1000000\n",
            "2021-11-07 09:39:40,717 DEV : loss 0.013645182363688946 - f1-score (micro avg)  0.7403\n",
            "2021-11-07 09:39:40,766 BAD EPOCHS (no improvement): 1\n",
            "2021-11-07 09:39:40,768 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:39:52,580 epoch 8 - iter 2/26 - loss 0.01035162 - samples/sec: 5.54 - lr: 0.100000\n",
            "2021-11-07 09:40:00,139 epoch 8 - iter 4/26 - loss 0.00963187 - samples/sec: 8.48 - lr: 0.100000\n",
            "2021-11-07 09:40:10,164 epoch 8 - iter 6/26 - loss 0.00819566 - samples/sec: 6.40 - lr: 0.100000\n",
            "2021-11-07 09:40:19,227 epoch 8 - iter 8/26 - loss 0.00783042 - samples/sec: 7.07 - lr: 0.100000\n",
            "2021-11-07 09:40:27,502 epoch 8 - iter 10/26 - loss 0.00779451 - samples/sec: 7.74 - lr: 0.100000\n",
            "2021-11-07 09:40:37,973 epoch 8 - iter 12/26 - loss 0.00814980 - samples/sec: 6.12 - lr: 0.100000\n",
            "2021-11-07 09:40:45,211 epoch 8 - iter 14/26 - loss 0.00833667 - samples/sec: 8.85 - lr: 0.100000\n",
            "2021-11-07 09:40:54,108 epoch 8 - iter 16/26 - loss 0.00853955 - samples/sec: 7.20 - lr: 0.100000\n",
            "2021-11-07 09:41:04,037 epoch 8 - iter 18/26 - loss 0.00919871 - samples/sec: 6.45 - lr: 0.100000\n",
            "2021-11-07 09:41:12,791 epoch 8 - iter 20/26 - loss 0.00924705 - samples/sec: 7.32 - lr: 0.100000\n",
            "2021-11-07 09:41:21,445 epoch 8 - iter 22/26 - loss 0.00949983 - samples/sec: 7.41 - lr: 0.100000\n",
            "2021-11-07 09:41:34,597 epoch 8 - iter 24/26 - loss 0.00955449 - samples/sec: 4.87 - lr: 0.100000\n",
            "2021-11-07 09:41:43,358 epoch 8 - iter 26/26 - loss 0.00944699 - samples/sec: 7.31 - lr: 0.100000\n",
            "2021-11-07 09:41:43,515 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:41:43,518 EPOCH 8 done: loss 0.0094 - lr 0.1000000\n",
            "2021-11-07 09:41:47,719 DEV : loss 0.017246287316083908 - f1-score (micro avg)  0.7869\n",
            "2021-11-07 09:41:47,768 BAD EPOCHS (no improvement): 0\n",
            "2021-11-07 09:41:47,770 saving best model\n",
            "2021-11-07 09:41:48,375 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:42:01,734 epoch 9 - iter 2/26 - loss 0.00781054 - samples/sec: 4.89 - lr: 0.100000\n",
            "2021-11-07 09:42:13,888 epoch 9 - iter 4/26 - loss 0.00773381 - samples/sec: 5.28 - lr: 0.100000\n",
            "2021-11-07 09:42:21,818 epoch 9 - iter 6/26 - loss 0.00670754 - samples/sec: 8.08 - lr: 0.100000\n",
            "2021-11-07 09:42:30,614 epoch 9 - iter 8/26 - loss 0.00710938 - samples/sec: 7.28 - lr: 0.100000\n",
            "2021-11-07 09:42:41,444 epoch 9 - iter 10/26 - loss 0.00701593 - samples/sec: 5.92 - lr: 0.100000\n",
            "2021-11-07 09:42:51,033 epoch 9 - iter 12/26 - loss 0.00662868 - samples/sec: 6.68 - lr: 0.100000\n",
            "2021-11-07 09:42:59,183 epoch 9 - iter 14/26 - loss 0.00751280 - samples/sec: 7.86 - lr: 0.100000\n",
            "2021-11-07 09:43:09,339 epoch 9 - iter 16/26 - loss 0.00723908 - samples/sec: 6.31 - lr: 0.100000\n",
            "2021-11-07 09:43:17,508 epoch 9 - iter 18/26 - loss 0.00710780 - samples/sec: 7.84 - lr: 0.100000\n",
            "2021-11-07 09:43:27,782 epoch 9 - iter 20/26 - loss 0.00707538 - samples/sec: 6.23 - lr: 0.100000\n",
            "2021-11-07 09:43:36,173 epoch 9 - iter 22/26 - loss 0.00692868 - samples/sec: 7.64 - lr: 0.100000\n",
            "2021-11-07 09:43:44,280 epoch 9 - iter 24/26 - loss 0.00728215 - samples/sec: 7.90 - lr: 0.100000\n",
            "2021-11-07 09:43:51,467 epoch 9 - iter 26/26 - loss 0.00757449 - samples/sec: 8.91 - lr: 0.100000\n",
            "2021-11-07 09:43:51,622 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:43:51,627 EPOCH 9 done: loss 0.0076 - lr 0.1000000\n",
            "2021-11-07 09:43:55,807 DEV : loss 0.017334049567580223 - f1-score (micro avg)  0.7263\n",
            "2021-11-07 09:43:55,858 BAD EPOCHS (no improvement): 1\n",
            "2021-11-07 09:43:55,861 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:44:03,598 epoch 10 - iter 2/26 - loss 0.00454844 - samples/sec: 8.54 - lr: 0.100000\n",
            "2021-11-07 09:44:15,004 epoch 10 - iter 4/26 - loss 0.00468958 - samples/sec: 5.62 - lr: 0.100000\n",
            "2021-11-07 09:44:22,955 epoch 10 - iter 6/26 - loss 0.00550283 - samples/sec: 8.06 - lr: 0.100000\n",
            "2021-11-07 09:44:33,812 epoch 10 - iter 8/26 - loss 0.00504700 - samples/sec: 5.90 - lr: 0.100000\n",
            "2021-11-07 09:44:45,740 epoch 10 - iter 10/26 - loss 0.00499625 - samples/sec: 5.37 - lr: 0.100000\n",
            "2021-11-07 09:44:54,569 epoch 10 - iter 12/26 - loss 0.00559703 - samples/sec: 7.58 - lr: 0.100000\n",
            "2021-11-07 09:45:04,100 epoch 10 - iter 14/26 - loss 0.00554000 - samples/sec: 6.72 - lr: 0.100000\n",
            "2021-11-07 09:45:12,635 epoch 10 - iter 16/26 - loss 0.00520646 - samples/sec: 7.51 - lr: 0.100000\n",
            "2021-11-07 09:45:21,619 epoch 10 - iter 18/26 - loss 0.00530636 - samples/sec: 7.13 - lr: 0.100000\n",
            "2021-11-07 09:45:28,098 epoch 10 - iter 20/26 - loss 0.00531914 - samples/sec: 9.88 - lr: 0.100000\n",
            "2021-11-07 09:45:36,953 epoch 10 - iter 22/26 - loss 0.00521398 - samples/sec: 7.24 - lr: 0.100000\n",
            "2021-11-07 09:45:46,439 epoch 10 - iter 24/26 - loss 0.00524823 - samples/sec: 6.75 - lr: 0.100000\n",
            "2021-11-07 09:45:59,922 epoch 10 - iter 26/26 - loss 0.00519259 - samples/sec: 4.75 - lr: 0.100000\n",
            "2021-11-07 09:46:00,085 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:46:00,087 EPOCH 10 done: loss 0.0052 - lr 0.1000000\n",
            "2021-11-07 09:46:04,282 DEV : loss 0.02134869061410427 - f1-score (micro avg)  0.7143\n",
            "2021-11-07 09:46:04,333 BAD EPOCHS (no improvement): 2\n",
            "2021-11-07 09:46:04,902 ----------------------------------------------------------------------------------------------------\n",
            "2021-11-07 09:46:04,905 loading file best-model.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2021-11-07 09:46:13,805 0.7093\t0.7262\t0.7176\t0.7024\n",
            "2021-11-07 09:46:13,808 \n",
            "Results:\n",
            "- F-score (micro) 0.7176\n",
            "- F-score (macro) 0.4947\n",
            "- Accuracy 0.7024\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1     0.7156    0.8571    0.7800        91\n",
            "          -1     0.7333    0.6769    0.7040        65\n",
            "           0     0.0000    0.0000    0.0000        12\n",
            "\n",
            "   micro avg     0.7093    0.7262    0.7176       168\n",
            "   macro avg     0.4830    0.5114    0.4947       168\n",
            "weighted avg     0.6713    0.7262    0.6949       168\n",
            " samples avg     0.7143    0.7262    0.7183       168\n",
            "\n",
            "2021-11-07 09:46:13,810 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.0173),\n",
              "  tensor(0.0170),\n",
              "  tensor(0.0162),\n",
              "  tensor(0.0135),\n",
              "  tensor(0.0142),\n",
              "  tensor(0.0140),\n",
              "  tensor(0.0136),\n",
              "  tensor(0.0172),\n",
              "  tensor(0.0173),\n",
              "  tensor(0.0213)],\n",
              " 'dev_score_history': [0.574585635359116,\n",
              "  0.5975609756097561,\n",
              "  0.5241379310344828,\n",
              "  0.7344632768361581,\n",
              "  0.7073170731707318,\n",
              "  0.7734806629834255,\n",
              "  0.7403314917127071,\n",
              "  0.7868852459016393,\n",
              "  0.7262569832402235,\n",
              "  0.7142857142857144],\n",
              " 'test_score': 0.7176470588235294,\n",
              " 'train_loss_history': [0.018629704683440402,\n",
              "  0.01723632013913497,\n",
              "  0.016668295361173962,\n",
              "  0.01468841315617839,\n",
              "  0.013153638003520596,\n",
              "  0.012298279794529804,\n",
              "  0.010871608226189336,\n",
              "  0.009446992728750683,\n",
              "  0.0075744906241453965,\n",
              "  0.005192594941777801]}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus: Corpus = ClassificationCorpus(data_folder,                                                                            \n",
        "                                      label_type='topic',\n",
        "                                      )\n",
        "\n",
        "label_dict = corpus.make_label_dictionary(label_type='topic')\n",
        "\n",
        "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, label_type='topic', multi_label=True)\n",
        "\n",
        "trainer = ModelTrainer(classifier, corpus)\n",
        "trainer.train('./', max_epochs=10,mini_batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyi4kDpxfG0v"
      },
      "source": [
        "As an output of model, Flair provides best model performance on the test set by following format at the end of output (see end of previous cell's output). \n",
        "\n",
        "Results:\n",
        "- **F-score** (micro) 0.7045\n",
        "- **F-score** (macro) 0.4809\n",
        "- **Accuracy** 0.6845\n",
        "\n",
        "By class:\n",
        "\n",
        "                 precision    recall  f1-score   support\n",
        "           1     0.7091    0.8571    0.7761        91\n",
        "          -1     0.7273    0.6154    0.6667        65\n",
        "           0     0.0000    0.0000    0.0000        12\n",
        "   \n",
        "\n",
        "As expected, Flair model has a good performance on positive news. Overall model performance is also better than statistical models. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "7.6.3. Deep Learning Based Sentiment Analysis_Flair.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}