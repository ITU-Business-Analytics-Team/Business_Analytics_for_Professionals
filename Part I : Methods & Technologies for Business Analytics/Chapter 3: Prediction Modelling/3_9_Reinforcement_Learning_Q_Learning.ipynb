{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.9.Reinforcement Learning_Q-Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITU-Business-Analytics-Team/Business_Analytics_for_Professionals/blob/main/Part%20I%20%3A%20Methods%20%26%20Technologies%20for%20Business%20Analytics/Chapter%203%3A%20Prediction%20Modelling/3_9_Reinforcement_Learning_Q_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT0tU-o4ubdY"
      },
      "source": [
        "# **Reinforcement Learning**\n",
        "## **Q-Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUfdn6lzRwWN"
      },
      "source": [
        "### **Problem Definition**\n",
        "The well-known maze problem is used to demonstrate the use of Q-learning algorithms. There is a ***n x n*** grid, which allows players to move in four directions: north, south, east, and west. Certain cells contain obtacles. The agent begins in one cell and works its way to the target cell. The objective is to determine the optimal sequence of motions that will result in the agent reaching the goal cell with the greatest reward.\n",
        "The Q-learning technique is employed in this case to solve this problem. The following steps in building the algorithm are as follows:\n",
        "1.   Define the environment as a class of objects in which agents operate.\n",
        "2. Define the agents as a class of objects.\n",
        "3. Finally, we trained our agent how to behave in the described environment  to achieve its purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhQCdw_Gm8NE"
      },
      "source": [
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrF0EXDum--m"
      },
      "source": [
        "#First define gridmaze environment as a class\n",
        "class Environment():\n",
        "  def __init__(self, height, width, blocked_cell, start_cell, end_cell, current_location):\n",
        "    #Define the dimensions of grid and cell features\n",
        "    self.height = height\n",
        "    self.width = width\n",
        "    self.blocked_cell = blocked_cell\n",
        "    self.end_cell = end_cell\n",
        "    self.start_cell = start_cell\n",
        "    self.current_location = current_location\n",
        "    self.state_space=[]\n",
        "    self.create_state_space()\n",
        "\n",
        "    #Define the immediate reward of each cell if the agent reach moves that cell\n",
        "    self.cell_reward = np.zeros((self.height, self.width))-1 #When agent moves from one cell to another, it gets -1 reward\n",
        "    self.cell_reward[self.end_cell[0], self.end_cell[1]] = 10 #if the agent reaches the end cell, gets 10 reward\n",
        "    self.cell_reward[self.blocked_cell[0], self.blocked_cell[1]] = -10 #if the agent tries to move the blocked cell, it gets -10 reward\n",
        "\n",
        "    self.actions = ['Left', 'Right', 'Up','Down'] # There are 4 possible actions of the agent.\n",
        "\n",
        "  def get_actions(self):\n",
        "      return self.actions\n",
        "  def create_state_space(self):    \n",
        "      for i in range(self.height):\n",
        "        for j in range(self.width):\n",
        "          if (i,j)!=self.blocked_cell:\n",
        "            self.state_space.append((i,j))    \n",
        "\n",
        "  def return_reward(self, next_location):\n",
        "     return self.cell_reward[next_location[0], next_location[1]]\n",
        "\n",
        "  def check_end_cell(self):\n",
        "      if self.current_location == self.end_cell:\n",
        "        return True\n",
        "  def check_blocked_cell(self):\n",
        "      if self.current_location == self.blocked_cell:\n",
        "        return True    \n",
        "  \n",
        "  def reset(self):\n",
        "    self.current_location = self.state_space[np.random.choice(len(self.state_space))]\n",
        "    while self.current_location==self.end_cell:\n",
        "      self.current_location = self.state_space[np.random.choice(len(self.state_space))]\n",
        "    \n",
        "  def step(self, action):\n",
        "        \"\"\"Directs the agent forward. If agent is at the border of or adjacent to a blocked cell, the agent's position is unaffected; however, \n",
        "        the agent takes a negative reward. Reward is returned by function.\"\"\"\n",
        "              \n",
        "        last_location = self.current_location\n",
        "        \n",
        "        # UP\n",
        "        if action == 'Up':\n",
        "            # If agent is at the top, stay still, collect reward\n",
        "            if last_location[0] == 0:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0]-1, last_location[1]) == self.blocked_cell:\n",
        "               reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0] - 1, self.current_location[1])\n",
        "                reward = self.return_reward(self.current_location)\n",
        "        \n",
        "        # DOWN\n",
        "        elif action == 'Down':\n",
        "            # If agent is at bottom, stay still, collect reward\n",
        "            if last_location[0] == self.height - 1:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0]+1, last_location[1]) == self.blocked_cell:\n",
        "                reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = (self.current_location[0] + 1, self.current_location[1])\n",
        "                reward = self.return_reward(self.current_location)\n",
        "            \n",
        "        # LEFT\n",
        "        elif action == 'Left':\n",
        "            # If agent is at the left, stay still, collect reward\n",
        "            if last_location[1] == 0:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0], last_location[1]-1) == self.blocked_cell:\n",
        "                reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0], self.current_location[1] - 1)\n",
        "                reward = self.return_reward(self.current_location)\n",
        "\n",
        "        # RIGHT\n",
        "        elif action == 'Right':\n",
        "            # If agent is at the right, stay still, collect reward\n",
        "            if last_location[1] == self.width - 1:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0], last_location[1]+1) == self.blocked_cell:\n",
        "                reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0], self.current_location[1] + 1)\n",
        "                reward = self.return_reward(self.current_location)\n",
        "                \n",
        "        return reward"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q82OYa2ho38S"
      },
      "source": [
        "environment = Environment(height=4, width=4, blocked_cell= (2,2), start_cell= (0,0), end_cell = (3,3), current_location = (0,0))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3VWAdeno7Jn"
      },
      "source": [
        "class Agent():\n",
        "  def __init__(self, environment, epsilon=0.05, gamma=0.9, alpha=0.1):\n",
        "    self.environment = environment\n",
        "    self.epsilon = epsilon\n",
        "    self.gamma = gamma\n",
        "    self.alpha = alpha\n",
        "    self.Qtable = {}\n",
        "    for s in environment.state_space:\n",
        "        self.Qtable[s]={}\n",
        "        for a in environment.actions:\n",
        "          self.Qtable [s][a] = 0 #Initializing the Q-table, filling it with zeros.\n",
        " \n",
        "  def epsilon_greedy(self, actions):\n",
        "    if np.random.uniform(0,1)<self.epsilon:\n",
        "        action = actions[np.random.randint(0,len(actions)-1)]\n",
        "    else:\n",
        "        maxValue = max(self.Qtable[self.environment.current_location].values())\n",
        "        action = np.random.choice([k for k, v in self.Qtable[self.environment.current_location].items() if v == maxValue])\n",
        "    return action\n",
        "    \n",
        "  def update_Qtable(self, old_state, action, new_state, reward):\n",
        "     max_q_value_in_new_state = max(self.Qtable[new_state].values())\n",
        "     current_q_value = self.Qtable[old_state][action]        \n",
        "     self.Qtable[old_state][action] = (1 - self.alpha) * current_q_value + self.alpha * (reward + self.gamma * max_q_value_in_new_state)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7NDDtbzp-zM"
      },
      "source": [
        "def play(environment, agent, episode, max_steps_per_episode):\n",
        "  reward_of_per_episode = []\n",
        "  for i in range(episode):\n",
        "     cumulative_reward = 0\n",
        "     step = 0\n",
        "     game_over = False\n",
        "    \n",
        "     while step<max_steps_per_episode and game_over == False:\n",
        "       old_state = environment.current_location\n",
        "       action = agent.epsilon_greedy(environment.actions)\n",
        "       reward = environment.step(action)\n",
        "       \n",
        "       new_state = environment.current_location\n",
        "       agent.update_Qtable(old_state, action, new_state, reward)\n",
        "\n",
        "       step+=1\n",
        "       cumulative_reward+=reward\n",
        "\n",
        "       if environment.check_end_cell():\n",
        "         game_over = True\n",
        "         environment.reset()\n",
        "      \n",
        "     reward_of_per_episode.append(cumulative_reward)\n",
        "   \n",
        "  return reward_of_per_episode"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjSOn8wLqGMW"
      },
      "source": [
        "environment = Environment(height=4, width=4, blocked_cell= (2,2), start_cell= (0,0), end_cell = (3,3), current_location = (0,0))\n",
        "agent = Agent(environment)\n",
        "reward_per_episode = play(environment, agent, episode=10000, max_steps_per_episode=1000)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqKz5nA1qKSf"
      },
      "source": [
        "# determine the policy from Q*\n",
        "policy = {}\n",
        "V = {}\n",
        "for s in environment.state_space:\n",
        "    if s!=environment.end_cell:\n",
        "      environment.current_location=s\n",
        "      maxValue = max(agent.Qtable[environment.current_location].values())\n",
        "      action = np.random.choice([k for k, v in agent.Qtable[environment.current_location].items() if v == maxValue])\n",
        "      policy[s] = action\n",
        "      V[s] = maxValue"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axoyQ2GFrHM1",
        "outputId": "31b1a70a-38d7-4dda-9a39-0fb01d1350f5"
      },
      "source": [
        "V"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): 1.8097999999999896,\n",
              " (0, 1): 3.1219999999999883,\n",
              " (0, 2): 4.57999999999999,\n",
              " (0, 3): 6.19999999999999,\n",
              " (1, 0): 3.1219999999999883,\n",
              " (1, 1): 4.57999999999999,\n",
              " (1, 2): 6.19999999999999,\n",
              " (1, 3): 7.999999999999996,\n",
              " (2, 0): 4.57999999999999,\n",
              " (2, 1): 6.19999999999999,\n",
              " (2, 3): 9.999999999999995,\n",
              " (3, 0): 6.19999999999999,\n",
              " (3, 1): 7.999999999999996,\n",
              " (3, 2): 9.999999999999995}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4mmsuHUrfXj"
      },
      "source": [
        "#Function to print policy on a grid\n",
        "def print_policy(policy,rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------------------\")\n",
        "        for j in range(columns):\n",
        "              a = policy.get((i,j), ' ')\n",
        "              print(\"  %s  |\" % a, end=\"\")\n",
        "        print(\"\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W780EzPUsHj2",
        "outputId": "4fe31c6f-5c5b-4889-c74b-ace49477ddd8"
      },
      "source": [
        "print_policy(policy,4,4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------\n",
            "  Right  |  Down  |  Down  |  Down  |\n",
            "---------------------------------------\n",
            "  Right  |  Down  |  Right  |  Down  |\n",
            "---------------------------------------\n",
            "  Right  |  Down  |     |  Down  |\n",
            "---------------------------------------\n",
            "  Right  |  Right  |  Right  |     |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNOGWfbNwGE1"
      },
      "source": [
        "#Function to print values on a grid\n",
        "def print_values(V, rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(columns):\n",
        "            v = V.get((i,j), 0)\n",
        "            if v >= 0:\n",
        "                print(\" %.2f|\" % v, end=\"\")\n",
        "            else:\n",
        "                print(\"%.2f|\" % v, end=\"\")\n",
        "        print(\"\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8SPLpzxzXY2",
        "outputId": "bade179d-16ca-42e4-a6a5-da2b24b916ab"
      },
      "source": [
        "print_values(V, 4,4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            " 1.81| 3.12| 4.58| 6.20|\n",
            "---------------------------\n",
            " 3.12| 4.58| 6.20| 8.00|\n",
            "---------------------------\n",
            " 4.58| 6.20| 0.00| 10.00|\n",
            "---------------------------\n",
            " 6.20| 8.00| 10.00| 0.00|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXGjlQlKUu_F"
      },
      "source": [
        "### **Results** \n",
        "The next figure demonstrates that after a few episodes, our Q-learning algorithm converges and our agent has learned how to behave optimally in the specified environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "izQW87CvzYDz",
        "outputId": "0eb0e8e8-630c-464a-9f51-35e03ca652d6"
      },
      "source": [
        "# Simple learning curve\n",
        "plt.plot(reward_per_episode)\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('Cumulative reward')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Cumulative reward')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}