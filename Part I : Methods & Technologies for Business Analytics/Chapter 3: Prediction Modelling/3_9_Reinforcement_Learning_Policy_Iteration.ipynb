{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.9. Reinforcement Learning_Policy Iteration.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ITU-Business-Analytics-Team/Business_Analytics_for_Professionals/blob/main/Part%20I%20%3A%20Methods%20%26%20Technologies%20for%20Business%20Analytics/Chapter%203%3A%20Prediction%20Modelling/3_9_Reinforcement_Learning_Policy_Iteration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uvUSoKKxfUB"
      },
      "source": [
        "# **Prediction Modelling: Machine Learning**\n",
        "## **Reinforcement Learning**\n",
        "Policy Iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYdgJKoezoRz"
      },
      "source": [
        "### **Problem Definition**\n",
        "The well-known maze problem is used to demonstrate the use of Policy Iteration  algorithm. There is a ***n x n*** grid, which allows players to move in four directions: north, south, east, and west. Certain cells contain obtacles. The agent begins in one cell and works its way to the target cell. The objective is to determine the optimal sequence of motions that will result in the agent reaching the goal cell with the greatest reward.\n",
        "The Q-learning technique is employed in this case to solve this problem. The following steps in building the algorithm are as follows:\n",
        "1.   Define the environment as a class of objects in which agents operate.\n",
        "2. Define the agents as a class of objects.\n",
        "3. Finally, we trained our agent how to behave in the described environment  to achieve its purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Os1sGU3vCZV8"
      },
      "source": [
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o8DxSfUCfdW"
      },
      "source": [
        "#First define gridmaze environment as a class\n",
        "class Environment():\n",
        "  def __init__(self, height, width, blocked_cell, start_cell, end_cell, current_location):\n",
        "    #Define the dimensions of grid and cell features\n",
        "    self.height = height\n",
        "    self.width = width\n",
        "    self.blocked_cell = blocked_cell\n",
        "    self.end_cell = end_cell\n",
        "    self.start_cell = start_cell\n",
        "    self.current_location = current_location\n",
        "    self.state_space=[]\n",
        "    self.create_state_space()\n",
        "\n",
        "    #Define the immediate reward of each cell if the agent reach moves that cell\n",
        "    self.cell_reward = np.zeros((self.height, self.width))-1 #When agent moves from one cell to another, it gets -1 reward\n",
        "    self.cell_reward[self.end_cell[0], self.end_cell[1]] = 10 #if the agent reaches the end cell, gets 10 reward\n",
        "    self.cell_reward[self.blocked_cell[0], self.blocked_cell[1]] = -10 #if the agent tries to move the blocked cell, it gets -10 reward\n",
        "\n",
        "    self.actions = ['Left', 'Right', 'Up','Down'] # There are 4 possible actions of the agent.\n",
        "\n",
        "  def get_actions(self):\n",
        "      return self.actions\n",
        "  def create_state_space(self):    \n",
        "      for i in range(self.height):\n",
        "        for j in range(self.width):\n",
        "          if (i,j)!=self.blocked_cell:\n",
        "            self.state_space.append((i,j))    \n",
        "\n",
        "  def return_reward(self, next_location):\n",
        "     return self.cell_reward[next_location[0], next_location[1]]\n",
        "\n",
        "  def check_end_cell(self):\n",
        "      if self.current_location == self.end_cell:\n",
        "        return True\n",
        "  def check_blocked_cell(self):\n",
        "      if self.current_location == self.blocked_cell:\n",
        "        return True    \n",
        "  def reset(self):\n",
        "    self.current_location = self.start_cell\n",
        "    \n",
        "  def step(self, action):\n",
        "        \"\"\"Directs the agent forward. If agent is at the border of or adjacent to a blocked cell, the agent's position is unaffected; however, \n",
        "        the agent takes a negative reward. Reward is returned by function.\"\"\"\n",
        "              \n",
        "        last_location = self.current_location\n",
        "        \n",
        "        # UP\n",
        "        if action == 'Up':\n",
        "            # If agent is at the top, stay still, collect reward\n",
        "            if last_location[0] == 0:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0]-1, last_location[1]) == self.blocked_cell:\n",
        "               reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0] - 1, self.current_location[1])\n",
        "                reward = self.return_reward(self.current_location)\n",
        "        \n",
        "        # DOWN\n",
        "        elif action == 'Down':\n",
        "            # If agent is at bottom, stay still, collect reward\n",
        "            if last_location[0] == self.height - 1:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0]+1, last_location[1]) == self.blocked_cell:\n",
        "                reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0] + 1, self.current_location[1])\n",
        "                reward = self.return_reward(self.current_location)\n",
        "            \n",
        "        # LEFT\n",
        "        elif action == 'Left':\n",
        "            # If agent is at the left, stay still, collect reward\n",
        "            if last_location[1] == 0:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0], last_location[1]-1) == self.blocked_cell:\n",
        "                reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0], self.current_location[1] - 1)\n",
        "                reward = self.return_reward(self.current_location)\n",
        "\n",
        "        # RIGHT\n",
        "        elif action == 'Right':\n",
        "            # If agent is at the right, stay still, collect reward\n",
        "            if last_location[1] == self.width - 1:\n",
        "                reward = self.return_reward(last_location)\n",
        "            elif (last_location[0], last_location[1]+1) == self.blocked_cell:\n",
        "                reward = self.return_reward(last_location)\n",
        "            else:\n",
        "                self.current_location = ( self.current_location[0], self.current_location[1] + 1)\n",
        "                reward = self.return_reward(self.current_location)\n",
        "                \n",
        "        return reward"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKPOpyUkCx72"
      },
      "source": [
        "environment = Environment(height=4, width=4, blocked_cell= (2,2), start_cell= (0,0), end_cell = (3,3), current_location = (0,0))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXCph8o_DCla"
      },
      "source": [
        "### define transition probabilities and rewards\n",
        "transition_probs = {}\n",
        "rewards = {}\n",
        "for s in environment.state_space:\n",
        "  for a in environment.actions:\n",
        "    environment.current_location=s\n",
        "    if not environment.check_end_cell():\n",
        "      if not environment.check_blocked_cell():\n",
        "        Reward = environment.step(a)\n",
        "        s2=environment.current_location\n",
        "        transition_probs[(s, a, s2)] = 1 #Note that the process is deterministic hence the probabilities are 1\n",
        "        rewards[(s, a)]=Reward"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rMhB9g1XRRj"
      },
      "source": [
        "#Generate a random policy\n",
        "policy={}\n",
        "for s in environment.state_space:\n",
        "  environment.current_location=s\n",
        "  if not environment.check_end_cell():\n",
        "    if not environment.check_blocked_cell():\n",
        "      action = environment.actions[np.random.randint(0,len(environment.actions)-1)]\n",
        "      policy[s]=action"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnH5d-btfoA8",
        "outputId": "9edbf4f6-1906-4c4d-ab82-46b680219c5a"
      },
      "source": [
        "policy"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(0, 0): 'Up',\n",
              " (0, 1): 'Left',\n",
              " (0, 2): 'Right',\n",
              " (0, 3): 'Up',\n",
              " (1, 0): 'Left',\n",
              " (1, 1): 'Up',\n",
              " (1, 2): 'Left',\n",
              " (1, 3): 'Right',\n",
              " (2, 0): 'Right',\n",
              " (2, 1): 'Left',\n",
              " (2, 3): 'Right',\n",
              " (3, 0): 'Up',\n",
              " (3, 1): 'Right',\n",
              " (3, 2): 'Right'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0wMMpFnVbt5"
      },
      "source": [
        "#Evaluates and computes the value of a given policy\n",
        "def policy_evaluation(policy):\n",
        "    # initialize V(s) = 0\n",
        "    V = {}\n",
        "    for s in environment.state_space:\n",
        "        V[s] = 0\n",
        "    SMALL_ENOUGH = 1e-3 # threshold for convergence\n",
        "    gamma = 0.9 # discount factor\n",
        "    # repeat until convergence\n",
        "    it = 0\n",
        "    while True:\n",
        "        biggest_change = 0\n",
        "        for s in environment.state_space:\n",
        "            environment.current_location=s\n",
        "            if environment.check_end_cell() or environment.check_blocked_cell():\n",
        "                V[s]=0\n",
        "            else:\n",
        "                old_v=V[s]\n",
        "                new_v = 0 # we will accumulate the answer\n",
        "                for a in environment.actions:\n",
        "                    for s2 in environment.state_space:\n",
        "                    # action probability is deterministic\n",
        "                        if policy.get(s)==a:\n",
        "                            action_prob=1\n",
        "                        else:\n",
        "                            action_prob=0\n",
        "                    # reward is a function of (s, a)\n",
        "                        r = rewards.get((s, a),0)\n",
        "                        new_v += action_prob * transition_probs.get((s, a, s2),0) * (r + gamma * V[s2])\n",
        "                # after done getting the new value, update the value table\n",
        "                V[s] = new_v\n",
        "                biggest_change = max(biggest_change, np.abs(old_v - V[s]))\n",
        "        print(\"iter:\", it, \"biggest_change:\", biggest_change)\n",
        "        it += 1\n",
        "        if biggest_change < SMALL_ENOUGH:\n",
        "            break\n",
        "    print(\"\\n\\n\")\n",
        "    return(V)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdJYbyl9GrnX",
        "outputId": "3afc25aa-015c-4c0f-d2a9-bdc0126566f0"
      },
      "source": [
        "#Policy Iteration Algorithm\n",
        "while True:\n",
        "    gamma = 0.9\n",
        "    # policy evaluation step - we already know how to do this!\n",
        "    V = policy_evaluation(policy)\n",
        "    # policy improvement step\n",
        "    is_policy_converged = True\n",
        "    for s in environment.state_space:\n",
        "        environment.current_location=s\n",
        "        if not environment.check_end_cell():\n",
        "            old_a = policy[s]\n",
        "            new_a = None\n",
        "            best_value = float('-inf')\n",
        "            # loop through all possible actions to find the best current action\n",
        "            for a in environment.actions:\n",
        "                v = 0\n",
        "                for s2 in environment.state_space:\n",
        "                # reward is a function of (s, a), 0 if not specified\n",
        "                    r = rewards.get((s, a), 0)\n",
        "                    v += transition_probs.get((s, a, s2), 0) * (r + gamma * V[s2])\n",
        "                if v > best_value:\n",
        "                    best_value = v\n",
        "                    new_a = a\n",
        "                  # new_a now represents the best action in this state\n",
        "                    policy[s] = new_a\n",
        "            if new_a != old_a:\n",
        "                is_policy_converged = False\n",
        "    if is_policy_converged:\n",
        "        break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 0 biggest_change: 10.0\n",
            "iter: 1 biggest_change: 9.0\n",
            "iter: 2 biggest_change: 1.3851000000000004\n",
            "iter: 3 biggest_change: 1.121931\n",
            "iter: 4 biggest_change: 0.9087641099999999\n",
            "iter: 5 biggest_change: 0.7360989291000006\n",
            "iter: 6 biggest_change: 0.5962401325709994\n",
            "iter: 7 biggest_change: 0.48295450738250967\n",
            "iter: 8 biggest_change: 0.43046720999999977\n",
            "iter: 9 biggest_change: 0.38742048900000015\n",
            "iter: 10 biggest_change: 0.3486784401000005\n",
            "iter: 11 biggest_change: 0.3138105960899997\n",
            "iter: 12 biggest_change: 0.28242953648099967\n",
            "iter: 13 biggest_change: 0.25418658283289997\n",
            "iter: 14 biggest_change: 0.2287679245496097\n",
            "iter: 15 biggest_change: 0.20589113209465015\n",
            "iter: 16 biggest_change: 0.18530201888518505\n",
            "iter: 17 biggest_change: 0.16677181699666477\n",
            "iter: 18 biggest_change: 0.1500946352969983\n",
            "iter: 19 biggest_change: 0.13508517176729917\n",
            "iter: 20 biggest_change: 0.12157665459056943\n",
            "iter: 21 biggest_change: 0.10941898913151249\n",
            "iter: 22 biggest_change: 0.0984770902183616\n",
            "iter: 23 biggest_change: 0.08862938119652597\n",
            "iter: 24 biggest_change: 0.0797664430768723\n",
            "iter: 25 biggest_change: 0.0717897987691849\n",
            "iter: 26 biggest_change: 0.06461081889226605\n",
            "iter: 27 biggest_change: 0.05814973700304016\n",
            "iter: 28 biggest_change: 0.052334763302736675\n",
            "iter: 29 biggest_change: 0.047101286972463186\n",
            "iter: 30 biggest_change: 0.042391158275215446\n",
            "iter: 31 biggest_change: 0.03815204244769532\n",
            "iter: 32 biggest_change: 0.034336838202925435\n",
            "iter: 33 biggest_change: 0.030903154382633247\n",
            "iter: 34 biggest_change: 0.027812838944369034\n",
            "iter: 35 biggest_change: 0.025031555049931598\n",
            "iter: 36 biggest_change: 0.022528399544938793\n",
            "iter: 37 biggest_change: 0.020275559590444914\n",
            "iter: 38 biggest_change: 0.018248003631400778\n",
            "iter: 39 biggest_change: 0.016423203268260522\n",
            "iter: 40 biggest_change: 0.014780882941435536\n",
            "iter: 41 biggest_change: 0.01330279464729145\n",
            "iter: 42 biggest_change: 0.011972515182561594\n",
            "iter: 43 biggest_change: 0.010775263664305257\n",
            "iter: 44 biggest_change: 0.009697737297875264\n",
            "iter: 45 biggest_change: 0.008727963568087915\n",
            "iter: 46 biggest_change: 0.007855167211278768\n",
            "iter: 47 biggest_change: 0.0070696504901519575\n",
            "iter: 48 biggest_change: 0.006362685441136051\n",
            "iter: 49 biggest_change: 0.005726416897022801\n",
            "iter: 50 biggest_change: 0.005153775207320521\n",
            "iter: 51 biggest_change: 0.004638397686587581\n",
            "iter: 52 biggest_change: 0.004174557917929533\n",
            "iter: 53 biggest_change: 0.003757102126137113\n",
            "iter: 54 biggest_change: 0.0033813919135230464\n",
            "iter: 55 biggest_change: 0.003043252722170209\n",
            "iter: 56 biggest_change: 0.002738927449954076\n",
            "iter: 57 biggest_change: 0.002465034704957958\n",
            "iter: 58 biggest_change: 0.002218531234461807\n",
            "iter: 59 biggest_change: 0.0019966781110163367\n",
            "iter: 60 biggest_change: 0.0017970102999136373\n",
            "iter: 61 biggest_change: 0.001617309269922984\n",
            "iter: 62 biggest_change: 0.0014555783429308633\n",
            "iter: 63 biggest_change: 0.0013100205086367112\n",
            "iter: 64 biggest_change: 0.0011790184577744611\n",
            "iter: 65 biggest_change: 0.001061116611996482\n",
            "iter: 66 biggest_change: 0.0009550049507964786\n",
            "\n",
            "\n",
            "\n",
            "iter: 0 biggest_change: 10.0\n",
            "iter: 1 biggest_change: 9.0\n",
            "iter: 2 biggest_change: 8.1\n",
            "iter: 3 biggest_change: 1.121931\n",
            "iter: 4 biggest_change: 0.9087641099999999\n",
            "iter: 5 biggest_change: 0.7360989291000006\n",
            "iter: 6 biggest_change: 0.5962401325709994\n",
            "iter: 7 biggest_change: 0.48295450738250967\n",
            "iter: 8 biggest_change: 0.43046720999999977\n",
            "iter: 9 biggest_change: 0.38742048900000015\n",
            "iter: 10 biggest_change: 0.3486784401000005\n",
            "iter: 11 biggest_change: 0.3138105960899997\n",
            "iter: 12 biggest_change: 0.28242953648099967\n",
            "iter: 13 biggest_change: 0.25418658283289997\n",
            "iter: 14 biggest_change: 0.2287679245496097\n",
            "iter: 15 biggest_change: 0.20589113209465015\n",
            "iter: 16 biggest_change: 0.18530201888518505\n",
            "iter: 17 biggest_change: 0.16677181699666477\n",
            "iter: 18 biggest_change: 0.1500946352969983\n",
            "iter: 19 biggest_change: 0.13508517176729917\n",
            "iter: 20 biggest_change: 0.12157665459056943\n",
            "iter: 21 biggest_change: 0.10941898913151249\n",
            "iter: 22 biggest_change: 0.0984770902183616\n",
            "iter: 23 biggest_change: 0.08862938119652597\n",
            "iter: 24 biggest_change: 0.0797664430768723\n",
            "iter: 25 biggest_change: 0.0717897987691849\n",
            "iter: 26 biggest_change: 0.06461081889226605\n",
            "iter: 27 biggest_change: 0.05814973700304016\n",
            "iter: 28 biggest_change: 0.052334763302736675\n",
            "iter: 29 biggest_change: 0.047101286972463186\n",
            "iter: 30 biggest_change: 0.042391158275215446\n",
            "iter: 31 biggest_change: 0.03815204244769532\n",
            "iter: 32 biggest_change: 0.034336838202925435\n",
            "iter: 33 biggest_change: 0.030903154382633247\n",
            "iter: 34 biggest_change: 0.027812838944369034\n",
            "iter: 35 biggest_change: 0.025031555049931598\n",
            "iter: 36 biggest_change: 0.022528399544938793\n",
            "iter: 37 biggest_change: 0.020275559590444914\n",
            "iter: 38 biggest_change: 0.018248003631400778\n",
            "iter: 39 biggest_change: 0.016423203268260522\n",
            "iter: 40 biggest_change: 0.014780882941435536\n",
            "iter: 41 biggest_change: 0.01330279464729145\n",
            "iter: 42 biggest_change: 0.011972515182561594\n",
            "iter: 43 biggest_change: 0.010775263664305257\n",
            "iter: 44 biggest_change: 0.009697737297875264\n",
            "iter: 45 biggest_change: 0.008727963568087915\n",
            "iter: 46 biggest_change: 0.007855167211278768\n",
            "iter: 47 biggest_change: 0.0070696504901519575\n",
            "iter: 48 biggest_change: 0.006362685441136051\n",
            "iter: 49 biggest_change: 0.005726416897022801\n",
            "iter: 50 biggest_change: 0.005153775207320521\n",
            "iter: 51 biggest_change: 0.004638397686587581\n",
            "iter: 52 biggest_change: 0.004174557917929533\n",
            "iter: 53 biggest_change: 0.003757102126137113\n",
            "iter: 54 biggest_change: 0.0033813919135230464\n",
            "iter: 55 biggest_change: 0.003043252722170209\n",
            "iter: 56 biggest_change: 0.002738927449954076\n",
            "iter: 57 biggest_change: 0.002465034704957958\n",
            "iter: 58 biggest_change: 0.002218531234461807\n",
            "iter: 59 biggest_change: 0.0019966781110163367\n",
            "iter: 60 biggest_change: 0.0017970102999136373\n",
            "iter: 61 biggest_change: 0.001617309269922984\n",
            "iter: 62 biggest_change: 0.0014555783429308633\n",
            "iter: 63 biggest_change: 0.0013100205086367112\n",
            "iter: 64 biggest_change: 0.0011790184577744611\n",
            "iter: 65 biggest_change: 0.001061116611996482\n",
            "iter: 66 biggest_change: 0.0009550049507964786\n",
            "\n",
            "\n",
            "\n",
            "iter: 0 biggest_change: 10.0\n",
            "iter: 1 biggest_change: 9.0\n",
            "iter: 2 biggest_change: 8.1\n",
            "iter: 3 biggest_change: 7.29\n",
            "iter: 4 biggest_change: 0.6561000000000003\n",
            "iter: 5 biggest_change: 0.59049\n",
            "iter: 6 biggest_change: 0.531441\n",
            "iter: 7 biggest_change: 0.47829690000000014\n",
            "iter: 8 biggest_change: 0.43046720999999977\n",
            "iter: 9 biggest_change: 0.38742048900000015\n",
            "iter: 10 biggest_change: 0.3486784401000005\n",
            "iter: 11 biggest_change: 0.3138105960899997\n",
            "iter: 12 biggest_change: 0.28242953648099967\n",
            "iter: 13 biggest_change: 0.25418658283289997\n",
            "iter: 14 biggest_change: 0.2287679245496097\n",
            "iter: 15 biggest_change: 0.20589113209465015\n",
            "iter: 16 biggest_change: 0.18530201888518505\n",
            "iter: 17 biggest_change: 0.16677181699666477\n",
            "iter: 18 biggest_change: 0.1500946352969983\n",
            "iter: 19 biggest_change: 0.13508517176729917\n",
            "iter: 20 biggest_change: 0.12157665459056943\n",
            "iter: 21 biggest_change: 0.10941898913151249\n",
            "iter: 22 biggest_change: 0.0984770902183616\n",
            "iter: 23 biggest_change: 0.08862938119652597\n",
            "iter: 24 biggest_change: 0.0797664430768723\n",
            "iter: 25 biggest_change: 0.0717897987691849\n",
            "iter: 26 biggest_change: 0.06461081889226605\n",
            "iter: 27 biggest_change: 0.05814973700304016\n",
            "iter: 28 biggest_change: 0.052334763302736675\n",
            "iter: 29 biggest_change: 0.047101286972463186\n",
            "iter: 30 biggest_change: 0.042391158275215446\n",
            "iter: 31 biggest_change: 0.03815204244769532\n",
            "iter: 32 biggest_change: 0.034336838202925435\n",
            "iter: 33 biggest_change: 0.030903154382633247\n",
            "iter: 34 biggest_change: 0.027812838944369034\n",
            "iter: 35 biggest_change: 0.025031555049931598\n",
            "iter: 36 biggest_change: 0.022528399544938793\n",
            "iter: 37 biggest_change: 0.020275559590444914\n",
            "iter: 38 biggest_change: 0.018248003631400778\n",
            "iter: 39 biggest_change: 0.016423203268260522\n",
            "iter: 40 biggest_change: 0.014780882941435536\n",
            "iter: 41 biggest_change: 0.01330279464729145\n",
            "iter: 42 biggest_change: 0.011972515182561594\n",
            "iter: 43 biggest_change: 0.010775263664305257\n",
            "iter: 44 biggest_change: 0.009697737297875264\n",
            "iter: 45 biggest_change: 0.008727963568087915\n",
            "iter: 46 biggest_change: 0.007855167211278768\n",
            "iter: 47 biggest_change: 0.0070696504901519575\n",
            "iter: 48 biggest_change: 0.006362685441136051\n",
            "iter: 49 biggest_change: 0.005726416897022801\n",
            "iter: 50 biggest_change: 0.005153775207320521\n",
            "iter: 51 biggest_change: 0.004638397686587581\n",
            "iter: 52 biggest_change: 0.004174557917929533\n",
            "iter: 53 biggest_change: 0.003757102126137113\n",
            "iter: 54 biggest_change: 0.0033813919135230464\n",
            "iter: 55 biggest_change: 0.003043252722170209\n",
            "iter: 56 biggest_change: 0.002738927449954076\n",
            "iter: 57 biggest_change: 0.002465034704957958\n",
            "iter: 58 biggest_change: 0.002218531234461807\n",
            "iter: 59 biggest_change: 0.0019966781110163367\n",
            "iter: 60 biggest_change: 0.0017970102999136373\n",
            "iter: 61 biggest_change: 0.001617309269922984\n",
            "iter: 62 biggest_change: 0.0014555783429308633\n",
            "iter: 63 biggest_change: 0.0013100205086367112\n",
            "iter: 64 biggest_change: 0.0011790184577744611\n",
            "iter: 65 biggest_change: 0.001061116611996482\n",
            "iter: 66 biggest_change: 0.0009550049507964786\n",
            "\n",
            "\n",
            "\n",
            "iter: 0 biggest_change: 10.0\n",
            "iter: 1 biggest_change: 9.0\n",
            "iter: 2 biggest_change: 8.1\n",
            "iter: 3 biggest_change: 7.29\n",
            "iter: 4 biggest_change: 6.561\n",
            "iter: 5 biggest_change: 0.59049\n",
            "iter: 6 biggest_change: 0.531441\n",
            "iter: 7 biggest_change: 0.47829690000000014\n",
            "iter: 8 biggest_change: 0.43046720999999977\n",
            "iter: 9 biggest_change: 0.38742048900000015\n",
            "iter: 10 biggest_change: 0.3486784401000005\n",
            "iter: 11 biggest_change: 0.3138105960899997\n",
            "iter: 12 biggest_change: 0.28242953648099967\n",
            "iter: 13 biggest_change: 0.25418658283289997\n",
            "iter: 14 biggest_change: 0.2287679245496097\n",
            "iter: 15 biggest_change: 0.20589113209465015\n",
            "iter: 16 biggest_change: 0.18530201888518505\n",
            "iter: 17 biggest_change: 0.16677181699666477\n",
            "iter: 18 biggest_change: 0.1500946352969983\n",
            "iter: 19 biggest_change: 0.13508517176729917\n",
            "iter: 20 biggest_change: 0.12157665459056943\n",
            "iter: 21 biggest_change: 0.10941898913151249\n",
            "iter: 22 biggest_change: 0.0984770902183616\n",
            "iter: 23 biggest_change: 0.08862938119652597\n",
            "iter: 24 biggest_change: 0.0797664430768723\n",
            "iter: 25 biggest_change: 0.0717897987691849\n",
            "iter: 26 biggest_change: 0.06461081889226605\n",
            "iter: 27 biggest_change: 0.05814973700304016\n",
            "iter: 28 biggest_change: 0.052334763302736675\n",
            "iter: 29 biggest_change: 0.047101286972463186\n",
            "iter: 30 biggest_change: 0.042391158275215446\n",
            "iter: 31 biggest_change: 0.03815204244769532\n",
            "iter: 32 biggest_change: 0.034336838202925435\n",
            "iter: 33 biggest_change: 0.030903154382633247\n",
            "iter: 34 biggest_change: 0.027812838944369034\n",
            "iter: 35 biggest_change: 0.025031555049931598\n",
            "iter: 36 biggest_change: 0.022528399544938793\n",
            "iter: 37 biggest_change: 0.020275559590444914\n",
            "iter: 38 biggest_change: 0.018248003631400778\n",
            "iter: 39 biggest_change: 0.016423203268260522\n",
            "iter: 40 biggest_change: 0.014780882941435536\n",
            "iter: 41 biggest_change: 0.01330279464729145\n",
            "iter: 42 biggest_change: 0.011972515182561594\n",
            "iter: 43 biggest_change: 0.010775263664305257\n",
            "iter: 44 biggest_change: 0.009697737297875264\n",
            "iter: 45 biggest_change: 0.008727963568087915\n",
            "iter: 46 biggest_change: 0.007855167211278768\n",
            "iter: 47 biggest_change: 0.0070696504901519575\n",
            "iter: 48 biggest_change: 0.006362685441136051\n",
            "iter: 49 biggest_change: 0.005726416897022801\n",
            "iter: 50 biggest_change: 0.005153775207320521\n",
            "iter: 51 biggest_change: 0.004638397686587581\n",
            "iter: 52 biggest_change: 0.004174557917929533\n",
            "iter: 53 biggest_change: 0.003757102126137113\n",
            "iter: 54 biggest_change: 0.0033813919135230464\n",
            "iter: 55 biggest_change: 0.003043252722170209\n",
            "iter: 56 biggest_change: 0.002738927449954076\n",
            "iter: 57 biggest_change: 0.002465034704957958\n",
            "iter: 58 biggest_change: 0.002218531234461807\n",
            "iter: 59 biggest_change: 0.0019966781110163367\n",
            "iter: 60 biggest_change: 0.0017970102999136373\n",
            "iter: 61 biggest_change: 0.001617309269922984\n",
            "iter: 62 biggest_change: 0.0014555783429308633\n",
            "iter: 63 biggest_change: 0.0013100205086367112\n",
            "iter: 64 biggest_change: 0.0011790184577744611\n",
            "iter: 65 biggest_change: 0.001061116611996482\n",
            "iter: 66 biggest_change: 0.0009550049507964786\n",
            "\n",
            "\n",
            "\n",
            "iter: 0 biggest_change: 10.0\n",
            "iter: 1 biggest_change: 9.0\n",
            "iter: 2 biggest_change: 8.1\n",
            "iter: 3 biggest_change: 7.29\n",
            "iter: 4 biggest_change: 6.561\n",
            "iter: 5 biggest_change: 5.9049000000000005\n",
            "iter: 6 biggest_change: 0\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWTPIvozVajQ"
      },
      "source": [
        "#Function to print values on a grid\n",
        "def print_values(V, rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------\")\n",
        "        for j in range(columns):\n",
        "            v = V.get((i,j), 0)\n",
        "            if v >= 0:\n",
        "                print(\" %.2f|\" % v, end=\"\")\n",
        "            else:\n",
        "                print(\"%.2f|\" % v, end=\"\")\n",
        "        print(\"\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsHJNIaNGvMD",
        "outputId": "22ae2166-98a0-4b75-e4ea-0b3e0b95752b"
      },
      "source": [
        "print_values(V, 4,4)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            " 1.81| 3.12| 4.58| 6.20|\n",
            "---------------------------\n",
            " 3.12| 4.58| 6.20| 8.00|\n",
            "---------------------------\n",
            " 4.58| 6.20| 0.00| 10.00|\n",
            "---------------------------\n",
            " 6.20| 8.00| 10.00| 0.00|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0gar4ZQMGv8"
      },
      "source": [
        "#Function to print policy on a grid\n",
        "def print_policy(policy,rows,columns):\n",
        "    for i in range(rows):\n",
        "        print(\"---------------------------------------\")\n",
        "        for j in range(columns):\n",
        "              a = policy.get((i,j), ' ')\n",
        "              print(\"  %s  |\" % a, end=\"\")\n",
        "        print(\"\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx2U9e2Oz51i"
      },
      "source": [
        "**Optimal Policy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ecHI3q4OLks",
        "outputId": "698f38bc-7526-41e0-8611-365a02124b20"
      },
      "source": [
        "print_policy(policy,4,4)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------\n",
            "  Right  |  Right  |  Right  |  Down  |\n",
            "---------------------------------------\n",
            "  Right  |  Right  |  Right  |  Down  |\n",
            "---------------------------------------\n",
            "  Right  |  Down  |     |  Down  |\n",
            "---------------------------------------\n",
            "  Right  |  Right  |  Right  |     |\n"
          ]
        }
      ]
    }
  ]
}